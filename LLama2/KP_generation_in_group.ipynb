{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic', 'stance', 'arguments', 'kep_points', 'predict_kps'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/ArgKP21+predictions(v3).csv')\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict via LLama2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"../conf/index.yaml\") as f:\n",
    "    credentials = yaml.safe_load(f)\n",
    "Llama2_api_token = credentials['environment_variables']['LLAMA2_API_TOKEN']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "def generating(topic, argument):\n",
    "    import replicate\n",
    "    replicate = replicate.Client(api_token=Llama2_api_token)\n",
    "    output = replicate.run(\n",
    "        \"meta/llama-2-70b-chat\",\n",
    "        input={\n",
    "            \"debug\": False,\n",
    "            \"top_p\": 1,\n",
    "            \"prompt\": argument,\n",
    "            \"temperature\": 0.5,\n",
    "            \"system_prompt\": f\"\"\"\n",
    "        You need to do key point analysis on a set of arguments from user. They are all about the topic \"{topic}\" You need to generate 5 sentences to summarize all arguments and return them.\n",
    "        \"\"\",\n",
    "            \"max_new_tokens\": 500,\n",
    "            \"min_new_tokens\": -1,\n",
    "            \"prompt_template\": \"[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{prompt} [/INST]\",\n",
    "            \"repetition_penalty\": 1.15\n",
    "        }\n",
    "    )\n",
    "    print(output)\n",
    "    # The meta/llama-2-70b-chat model can stream output as it's running.\n",
    "    # The predict method returns an iterator, and you can iterate over that output.\n",
    "    for item in output:\n",
    "        print(item, end=\"\")\n",
    "    extracted_sentences = []\n",
    "    try:\n",
    "        if not any(['\\n\\n1' in output, '\\n\\n*' in output]):\n",
    "            print(\"Neither '\\n\\n1' nor '\\n\\n*' found in output. Regenerating string...\")\n",
    "            return generating(topic, argument)\n",
    "        else:\n",
    "            if '\\n\\n1' in output:\n",
    "                indices = [\n",
    "                (output.index('\\n\\n1'), output.index('\\n2')),\n",
    "                (output.index('\\n2'), output.index('\\n3')),\n",
    "                (output.index('\\n3'), output.index('\\n4')),\n",
    "                (output.index('\\n4'), output.index('\\n5')),\n",
    "                (output.index('\\n5'), len(output))\n",
    "                ]\n",
    "                # Extract the sentences using the indices\n",
    "                for start, end in indices:\n",
    "                    sentence = ''.join(output[start+2:end])\n",
    "                    extracted_sentences.append(sentence.strip())\n",
    "            elif '\\n\\n*' in output:\n",
    "                    # Join the list into a single string\n",
    "                joined_text = ' '.join(output)\n",
    "                first_delimiter_index = joined_text.find('\\n*')\n",
    "                right_part = joined_text[first_delimiter_index:]\n",
    "                extracted_sentences = [sentence.strip() for sentence in right_part.split('\\n*')[1:] if sentence.strip()]\n",
    "            # else:\n",
    "            #     output = ' '.join(output)\n",
    "            #     # Find the index of the end of the introductory phrase\n",
    "            #     intro_end_index = output.find(\":\") + 2\n",
    "            #     # Extract the main text after the introductory phrase\n",
    "            #     main_text = output[intro_end_index:]\n",
    "            #     # Use regular expression to split the main text into sentences\n",
    "            #     sentences = re.split(r'(?<=[.!?])\\s+', main_text)\n",
    "            #     extracted_sentences = [sentence.strip() for sentence in sentences]\n",
    "            # Check if the list can transform in str of standard list\n",
    "            str_final_list = str(extracted_sentences)\n",
    "            list_test = ast.literal_eval(str_final_list)\n",
    "            return list_test\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error: {e}. Regenerating string...\")\n",
    "        return generating(topic, argument)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50: \n",
      "[' Sure', ',', ' here', ' are', ' ', '5', ' sentences', ' summar', 'izing', ' the', ' arguments', ' for', ' subs', 'id', 'izing', ' journal', 'ism', ':', '\\n', '\\n', 'J', 'ournal', 'ism', ' plays', ' a', ' vital', ' role', ' in', ' dem', 'ocracy', ' by', ' keeping', ' the', ' public', ' informed', ' and', ' holding', ' those', ' in', ' power', ' account', 'able', ',', ' and', ' subs', 'id', 'izing', ' it', ' would', ' ensure', ' that', ' this', ' important', ' work', ' continues', '.', ' Sub', 's', 'id', 'izing', ' journal', 'ism', ' would', ' allow', ' for', ' more', ' in', '-', 'depth', ' reporting', ' and', ' a', ' wider', ' range', ' of', ' view', 'points', ',', ' as', ' well', ' as', ' help', ' to', ' combat', ' the', ' influence', ' of', ' fake', ' news', ' and', ' bi', 'ased', ' sources', '.', ' Additionally', ',', ' subs', 'id', 'ies', ' could', ' help', ' to', ' support', ' local', ' journal', 'ism', ' and', ' ensure', ' that', ' communities', ' have', ' access', ' to', ' accurate', ' and', ' tim', 'ely', ' information', ' about', ' local', ' events', '.', ' Furthermore', ',', ' subs', 'id', 'izing', ' journal', 'ism', ' would', ' help', ' to', ' level', ' the', ' playing', ' field', ' and', ' promote', ' divers', 'ity', ' in', ' the', ' field', ',', ' allowing', ' for', ' a', ' wider', ' range', ' of', ' voices', ' and', ' pers', 'pect', 'ives', ' to', ' be', ' heard', '.', ' Finally', ',', ' supporting', ' journal', 'ism', ' through', ' subs', 'id', 'ies', ' would', ' be', ' an', ' invest', 'ment', ' in', ' dem', 'ocracy', ' and', ' the', ' well', '-', 'be', 'ing', ' of', ' society', ',', ' as', ' well', ' as', ' a', ' way', ' to', ' promote', ' trans', 'par', 'ency', ' and', ' account', 'ability', ' in', ' government', '.']\n",
      " Sure, here are 5 sentences summarizing the arguments for subsidizing journalism:\n",
      "\n",
      "Journalism plays a vital role in democracy by keeping the public informed and holding those in power accountable, and subsidizing it would ensure that this important work continues. Subsidizing journalism would allow for more in-depth reporting and a wider range of viewpoints, as well as help to combat the influence of fake news and biased sources. Additionally, subsidies could help to support local journalism and ensure that communities have access to accurate and timely information about local events. Furthermore, subsidizing journalism would help to level the playing field and promote diversity in the field, allowing for a wider range of voices and perspectives to be heard. Finally, supporting journalism through subsidies would be an investment in democracy and the well-being of society, as well as a way to promote transparency and accountability in government.Neither '\n",
      "\n",
      "1' nor '\n",
      "\n",
      "*' found in output. Regenerating string...\n",
      "[' Sure', ',', ' here', ' are', ' ', '5', ' sentences', ' summar', 'izing', ' the', ' arguments', ' for', ' subs', 'id', 'izing', ' journal', 'ism', ':', '\\n', '\\n', 'J', 'ournal', 'ism', ' plays', ' a', ' cru', 'cial', ' role', ' in', ' inform', 'ing', ' the', ' public', ' and', ' holding', ' those', ' in', ' power', ' account', 'able', ',', ' and', ' therefore', ' deser', 'ves', ' government', ' support', '.', ' Sub', 's', 'id', 'izing', ' journal', 'ism', ' can', ' help', ' ensure', ' that', ' high', '-', 'quality', ' reporting', ' continues', ' to', ' be', ' produced', ',', ' even', ' in', ' the', ' face', ' of', ' decl', 'ining', ' advert', 'ising', ' re', 'venue', '.', ' It', ' can', ' also', ' help', ' lower', ' the', ' bar', 'riers', ' to', ' entry', ' for', ' new', ' journal', 'ists', ' and', ' promote', ' divers', 'ity', ' in', ' the', ' field', '.', ' Additionally', ',', ' subs', 'id', 'izing', ' journal', 'ism', ' can', ' help', ' combat', ' the', ' spread', ' of', ' mis', 'information', ' and', ' promote', ' fact', '-', 'based', ' reporting', '.', ' Finally', ',', ' supporting', ' journal', 'ism', ' is', ' essential', ' for', ' maintain', 'ing', ' a', ' health', 'y', ' dem', 'ocracy', ',', ' as', ' it', ' provides', ' citizens', ' with', ' the', ' information', ' they', ' need', ' to', ' make', ' informed', ' dec', 'isions', '.']\n",
      " Sure, here are 5 sentences summarizing the arguments for subsidizing journalism:\n",
      "\n",
      "Journalism plays a crucial role in informing the public and holding those in power accountable, and therefore deserves government support. Subsidizing journalism can help ensure that high-quality reporting continues to be produced, even in the face of declining advertising revenue. It can also help lower the barriers to entry for new journalists and promote diversity in the field. Additionally, subsidizing journalism can help combat the spread of misinformation and promote fact-based reporting. Finally, supporting journalism is essential for maintaining a healthy democracy, as it provides citizens with the information they need to make informed decisions.Neither '\n",
      "\n",
      "1' nor '\n",
      "\n",
      "*' found in output. Regenerating string...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m topic \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m argument \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marguments\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 5\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgenerating\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margument\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(result))\n",
      "Cell \u001B[1;32mIn[4], line 31\u001B[0m, in \u001B[0;36mgenerating\u001B[1;34m(topic, argument)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m([\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output]):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNeither \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m nor \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m found in output. Regenerating string...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgenerating\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margument\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output:\n",
      "Cell \u001B[1;32mIn[4], line 31\u001B[0m, in \u001B[0;36mgenerating\u001B[1;34m(topic, argument)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m([\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output]):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNeither \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m nor \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m found in output. Regenerating string...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgenerating\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margument\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output:\n",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m, in \u001B[0;36mgenerating\u001B[1;34m(topic, argument)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mreplicate\u001B[39;00m\n\u001B[0;32m      5\u001B[0m replicate \u001B[38;5;241m=\u001B[39m replicate\u001B[38;5;241m.\u001B[39mClient(api_token\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr8_Xyt7cpubCOSsrKdr7VAragV8W1eAG521NStVx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mreplicate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmeta/llama-2-70b-chat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdebug\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43margument\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem_prompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;43m    You need to do key point analysis on a set of arguments from user. They are all about the topic \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtopic\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m You need to generate 5 sentences to summarize all arguments and return them.\u001B[39;49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;43m    \u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_new_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmin_new_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt_template\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m[INST] <<SYS>>\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;132;43;01m{system_prompt}\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m<</SYS>>\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;132;43;01m{prompt}\u001B[39;49;00m\u001B[38;5;124;43m [/INST]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrepetition_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1.15\u001B[39;49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# The meta/llama-2-70b-chat model can stream output as it's running.\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# The predict method returns an iterator, and you can iterate over that output.\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\replicate\\client.py:157\u001B[0m, in \u001B[0;36mClient.run\u001B[1;34m(self, ref, input, **params)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    149\u001B[0m     ref: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28minput\u001B[39m: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams: Unpack[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredictions.CreatePredictionParams\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    152\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Any, Iterator[Any]]:  \u001B[38;5;66;03m# noqa: ANN401\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;124;03m    Run a model and wait for its output.\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m run(\u001B[38;5;28mself\u001B[39m, ref, \u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "File \u001B[1;32mG:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\replicate\\run.py:58\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(client, ref, input, **params)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m version \u001B[38;5;129;01mand\u001B[39;00m (iterator \u001B[38;5;241m:=\u001B[39m _make_output_iterator(version, prediction)):\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m iterator\n\u001B[1;32m---> 58\u001B[0m \u001B[43mprediction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prediction\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ModelError(prediction\u001B[38;5;241m.\u001B[39merror)\n",
      "File \u001B[1;32mG:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\replicate\\prediction.py:144\u001B[0m, in \u001B[0;36mPrediction.wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03mWait for prediction to finish.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcanceled\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 144\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll_interval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreload()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in df.iloc[50:].iterrows():\n",
    "    print(str(index)+\": \")\n",
    "    topic = row['topic']\n",
    "    argument = row['arguments']\n",
    "    result = generating(topic, argument)\n",
    "    print(\"\\n\")\n",
    "    print(len(result))\n",
    "    str_result = str(result)\n",
    "    df.at[index, 'predict_kps'] = str_result\n",
    "\n",
    "# df.to_csv('./data/ArgKP21+predictions(v3).csv', index=False)\n",
    "# print(\"Add new data successfully!!!!!\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add new data successfully!!!!!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('./data/ArgKP21+predictions(v3).csv', index=False)\n",
    "print(\"Add new data successfully!!!!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check chinese Characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic', 'stance', 'arguments', 'kep_points', 'predict_kps'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/ArgKP21+predictions(v3).csv')\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "def contains_chinese(text):\n",
    "    # Regular expression pattern for Chinese characters\n",
    "    chinese_pattern = re.compile('[\\u4e00-\\u9fff]+')\n",
    "\n",
    "    # Search for Chinese characters in the text\n",
    "    if chinese_pattern.search(text):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: \n",
      "2: \n",
      "3: \n",
      "4: \n",
      "5: \n",
      "6: \n",
      "7: \n",
      "8: \n",
      "9: \n",
      "10: \n",
      "11: \n",
      "12: \n",
      "13: \n",
      "14: \n",
      "15: \n",
      "16: \n",
      "17: \n",
      "18: \n",
      "19: \n",
      "20: \n",
      "21: \n",
      "22: \n",
      "23: \n",
      "24: \n",
      "25: \n",
      "26: \n",
      "27: \n",
      "28: \n",
      "29: \n",
      "30: \n",
      "31: \n",
      "32: \n",
      "33: \n",
      "34: \n",
      "35: \n",
      "36: \n",
      "37: \n",
      "38: \n",
      "39: \n",
      "40: \n",
      "41: \n",
      "42: \n",
      "43: \n",
      "44: \n",
      "45: \n",
      "46: \n",
      "47: \n",
      "48: \n",
      "49: \n",
      "50: \n",
      "51: \n",
      "52: \n",
      "53: \n",
      "54: \n",
      "55: \n",
      "56: \n",
      "57: \n",
      "58: \n",
      "59: \n",
      "60: \n",
      "61: \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "for index, row in df.iterrows():\n",
    "    print(str(index)+\": \")\n",
    "    kps = ast.literal_eval(df.at[index,'predict_kps'])\n",
    "    for kp in kps:\n",
    "        if contains_chinese(kp): print(\"Yes\")\n",
    "        # else: print(\"No\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}