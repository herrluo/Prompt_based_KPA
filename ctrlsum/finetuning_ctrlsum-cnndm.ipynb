{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic', 'stance', 'arguments', 'kep_points', 'predict_kps'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../result/ArgKP21+predictions(v2).csv')\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import ast\n",
    "train_input = []\n",
    "train_summary = []\n",
    "val_input = []\n",
    "val_summary = []\n",
    "test_input = []\n",
    "test_summary = []\n",
    "for index,row in df.iterrows():\n",
    "    input = ' '\n",
    "    output = ' '\n",
    "    arguments = df.at[index, 'arguments']\n",
    "    summaries = df.at[index, 'predict_kps']\n",
    "    arguments = ast.literal_eval(arguments)\n",
    "    summaries = ast.literal_eval(summaries)\n",
    "    for argument in arguments:\n",
    "        if not argument.endswith('.'):\n",
    "            argument += '.'\n",
    "        input += argument\n",
    "    for summary in summaries:\n",
    "        if not summary.endswith('.'):\n",
    "            summary += '.'\n",
    "        output += summary\n",
    "    if index in (56,57,58,59,60,61):\n",
    "        test_input.append(input)\n",
    "        test_summary.append(output)\n",
    "    elif index in (8,9,16,17,18,19,30,31):\n",
    "        val_input.append(input)\n",
    "        val_summary.append(output)\n",
    "    else:\n",
    "        train_input.append(input)\n",
    "        train_summary.append(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, texts, summaries, tokenizer, max_input_length=512, max_target_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.texts[idx]\n",
    "        target_summary = self.summaries[idx]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        targets = self.tokenizer.encode(\n",
    "            target_summary,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': targets.flatten()\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "class SummarizationModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, tokenizer, learning_rate=2e-5):\n",
    "        super(SummarizationModel, self).__init__()\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "        loss = outputs.loss\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "        loss = outputs.loss\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "        loss = outputs.loss\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=self.learning_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Phase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory G:\\Program Files\\KPA prompt-based\\ctrlsum\\checkpoint exists and is not empty.\n",
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 406 M \n",
      "-------------------------------------------------------\n",
      "406 M     Trainable params\n",
      "0         Non-trainable params\n",
      "406 M     Total params\n",
      "1,625.162 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ee33c7eeaf24869bdd3c7a28754e4a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"hyunwoongko/ctrlsum-cnndm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_dataset = SummarizationDataset(train_input, train_summary, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_input, val_summary, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)\n",
    "model = SummarizationModel(model_name=model_name, tokenizer=tokenizer)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./checkpoint',\n",
    "    filename='nli_model-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# Determine the accelerator type based on GPU availability\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    min_epochs=0,  # Adjust as needed\n",
    "    max_epochs=20,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    accelerator=accelerator  # Automatically selects GPU if available, otherwise uses CPU\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "print(\"Train finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "G:\\Program Files\\KPA prompt-based\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_checkpoint = './checkpoint/nli_model-epoch=02-val_loss=1.85.ckpt'\n",
    "# Load the model from the checkpoint\n",
    "model_name = \"hyunwoongko/ctrlsum-cnndm\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "loaded_model = SummarizationModel.load_from_checkpoint(model_name=model_name,tokenizer = tokenizer, checkpoint_path=model_checkpoint )\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "print(\"hello world\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "test_argument_list = df.at[61,'arguments']\n",
    "test_arguments = ast.literal_eval(test_argument_list)\n",
    "test_arguments = test_arguments[:50]\n",
    "print(len(test_arguments))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "test_input = ' '\n",
    "for argument in test_arguments:\n",
    "    if not argument.endswith('.'):\n",
    "        argument += '.'\n",
    "    test_input += argument"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he state of anguish that many of the large cities of the USA are experiencing goes against the quality of life. Laws in some inflexible cases go against ordinary citizens.healthcare and education are extremely expensive to middle class.High crime rates, racism, xenophobia, high tax rates, many negative points, it is not a good country to live in.I'm afraid there are some worries, because of the racism there, and that strangers might not get the same good treatment.If you have a dark skin color or you are Latin the opportunities are reduced to the minimum ... I consider that there are other countries like Europe for example ... the United States is not the chimera.in some parts you are not given the opportunity to work just because you are an immigrant or because of your skin color.in the USA the health system is very expensive and discriminates against the poor population.It could be said that they are also in the middle of the war and are prone to one day suffer a disaster.it doesn't  have free healthcare, and enough gun control laws.it doesn't provide it's citizens with free healthcare.it doesn`t have free healthcare and it has a lot of shootings and racist systems in place.it is a country with a stressful pace of life.It is a country with many rules and restrictions, all of which must be met.It is very difficult to live in the USA because the cost of living is too high and even going to the doctor can be extremely expensive.It is very unsafe with the large number of attacks that there are.low payment in some jobs, which will make it difficult to handle high prices.No, it is a country with many restrictions on immigrants.No, it is a very strict country with an unstoppable political system.No, since it is a culture that forces unbridled consumerism, which leads to an endless search for money and status.Not because it is a country with many restrictions for immigrants.not because taxes are high and expensive.not everything is like in the movies the united states has a lot of inequality.Not the best place for people of color.on the contrary I do not recommend it for Latin American foreigners there is a lot of racism.recently there was a lot of political problems that I'm afraid it will make it hard to live there plus some regions don't have a lot of  attention from the government.still in some states there are many robberies and other crimes that involve innocent people.The government watches you too much.The health sector, despite being very good, is excessively expensive, as is healthy food.The unequal levels of life style means there is so much unrest in the USA that it is not a good country to live in.The United States  has long been a hotbed of racism against minority cultures.The United States could have better management of wealth and others worse, the government does not work, that is why it would not be my best option.The United States has abyssal taxes, I don't like living here.The United States has made a very poor performance of its resources to govern.The United States is not the best for its culture of war.The United States is now ranked among the world's worst places to move to, due to rapidly increasing costs of living, health care and basic education.the us culture promotes materialism.The USA has a huge gun violence problem, from frequent mass shootings to self-inflicted gun shot wounds, the statistics are staggering.the usa has the highest rate of mental illness in the first world.The USA is a bad country to live in because some people are aggressive.The USA is a greatly divided country that can make it difficult to succeed.The USA is a very capitalist country; it does not provide universal health care or education for its citizens.The USA is no longer a good place to live. It has become a haven for refugees, a social services country and a place where criminals have more rights than law abiding citizens.The USA is not a good country to live in because is always in war with other country.the USA is not a good country to live in because it fails to provide affordable healthcare to all its citizens.The USA is not a good country to live in because many people are racists.The USA is not a good country to live in because of all the racial and political divisions and because of all the mass shootings due to a resistance against gun control regulations.The USA is not a good country to live in because some people don't respect the immigrants.The USA is not a good country to live in because there is so much government control.The USA is not a good country to live in, a lot of danger due to lacks of gun regulation.The USA is not a good place to live in because of the wide variance between rich and poor.  The poorest in society don't have access to either good health care or an adequate benefits system.\n"
     ]
    }
   ],
   "source": [
    "print(test_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:  The USA is not a good country to live in because of its high cost of living and lack of healthcare for all citizens.The USA has a high rate of violence and is often seen as a hotbed of racism against minority cultures.The country's political system is often viewed as being too restrictive, leading to a lack of political stability and a perceived lack of accomplishment.The U.S. does not provide universal health care or education, making it difficult for the middle class to access healthcare and education.The culture of unbridled consumerism, fueled by an endless search for money and status, makes the USA a difficult place to live.\n"
     ]
    }
   ],
   "source": [
    "# Example text input\n",
    "# input_text = \"today plan => My name is Kevin. I love dogs. I loved dogs from 1996. Today, I'm going to walk on street with my dogs\"\n",
    "input_text = \"USA good=> \"+test_input\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = loaded_model.model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], num_beams=5,max_length=300, early_stopping=True)\n",
    "\n",
    "# Decode and print generated summary\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated Summary:\", generated_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###\n",
    "'''\n",
    "Generated Summary:  The USA is not a good country to live in because of its high cost of living and lack of healthcare for all citizens.The USA has a high rate of violence and is often seen as a hotbed of racism against minority cultures.The country's political system is often viewed as being too restrictive, leading to a lack of political stability and a perceived lack of accomplishment.The U.S. does not provide universal health care or education, making it difficult for the middle class to access healthcare and education.The culture of unbridled consumerism, fueled by an endless search for money and status, makes the USA a difficult place to live.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The USA is not a good country to live in because of its high cost of living and lack of healthcare for all citizens.\n",
      "Normalized Length: 1.0000\n",
      "Normalized Grammar Score: 0.0000\n",
      "Normalized FKGL Score: 0.0635\n",
      "Normalized GFI Score: 0.0000\n",
      "Sentence: The USA has a high rate of violence and is often seen as a hotbed of racism against minority cultures.\n",
      "Normalized Length: 0.0000\n",
      "Normalized Grammar Score: 0.0000\n",
      "Normalized FKGL Score: 0.0000\n",
      "Normalized GFI Score: 0.1460\n",
      "Sentence: The country's political system is often viewed as being too restrictive, leading to a lack of political stability and a perceived lack of accomplishment.\n",
      "Normalized Length: 1.0000\n",
      "Normalized Grammar Score: 0.0000\n",
      "Normalized FKGL Score: 1.0000\n",
      "Normalized GFI Score: 1.0000\n",
      "Sentence: The U.S. does not provide universal health care or education, making it difficult for the middle class to access healthcare and education.\n",
      "Normalized Length: 0.5000\n",
      "Normalized Grammar Score: 0.0000\n",
      "Normalized FKGL Score: 0.6984\n",
      "Normalized GFI Score: 0.5960\n",
      "Sentence: The culture of unbridled consumerism, fueled by an endless search for money and status, makes the USA a difficult place to live.\n",
      "Normalized Length: 0.5000\n",
      "Normalized Grammar Score: 0.0000\n",
      "Normalized FKGL Score: 0.3175\n",
      "Normalized GFI Score: 0.2340\n",
      "PageRank Score: 0.3914 - Sentence: The country's political system is often viewed as being too restrictive, leading to a lack of political stability and a perceived lack of accomplishment.\n",
      "PageRank Score: 0.2462 - Sentence: The U.S. does not provide universal health care or education, making it difficult for the middle class to access healthcare and education.\n",
      "PageRank Score: 0.1581 - Sentence: The USA is not a good country to live in because of its high cost of living and lack of healthcare for all citizens.\n",
      "PageRank Score: 0.1567 - Sentence: The culture of unbridled consumerism, fueled by an endless search for money and status, makes the USA a difficult place to live.\n",
      "PageRank Score: 0.0476 - Sentence: The USA has a high rate of violence and is often seen as a hotbed of racism against minority cultures.\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "import language_tool_python\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"The USA is not a good country to live in because of its high cost of living and lack of healthcare for all citizens.\",\n",
    "    \"The USA has a high rate of violence and is often seen as a hotbed of racism against minority cultures.\",\n",
    "    \"The country's political system is often viewed as being too restrictive, leading to a lack of political stability and a perceived lack of accomplishment.\",\n",
    "    \"The U.S. does not provide universal health care or education, making it difficult for the middle class to access healthcare and education.\",\n",
    "    \"The culture of unbridled consumerism, fueled by an endless search for money and status, makes the USA a difficult place to live.\"\n",
    "]\n",
    "\n",
    "# Function to calculate length of sentences\n",
    "def calculate_length(sentences):\n",
    "    return np.array([len(sentence.split()) for sentence in sentences])\n",
    "\n",
    "\n",
    "# Function to calculate grammar score using language_tool_python\n",
    "def calculate_grammar_score(sentences):\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    grammar_scores = []\n",
    "    for sentence in sentences:\n",
    "        matches = tool.check(sentence)\n",
    "        if len(matches) > 0:\n",
    "            grammar_score = len(matches)  # Number of grammar errors found\n",
    "        else:\n",
    "            grammar_score = 0  # Default score when no errors found\n",
    "        grammar_scores.append(grammar_score)\n",
    "    return np.array(grammar_scores)\n",
    "\n",
    "# Function to calculate FKGL scores using textstat library\n",
    "def calculate_fkgl(sentences):\n",
    "    return np.array([textstat.flesch_kincaid_grade(sentence) for sentence in sentences])\n",
    "\n",
    "# Dummy function for GFI score (replace with real implementation)\n",
    "def calculate_gfi(sentences):\n",
    "    return np.array([textstat.gunning_fog(sentence) for sentence in sentences])  # Example: random scores between 0 and 1\n",
    "\n",
    "# Step 1: Calculate metrics for each sentence\n",
    "lengths = calculate_length(sentences)\n",
    "grammar_scores = calculate_grammar_score(sentences)\n",
    "fkgl_scores = calculate_fkgl(sentences)\n",
    "gfi_scores = calculate_gfi(sentences)\n",
    "\n",
    "# Step 2: Normalize metrics\n",
    "\n",
    "def normalize_metric(metric):\n",
    "    min_value = np.min(metric)\n",
    "    max_value = np.max(metric)\n",
    "\n",
    "    if max_value - min_value == 0:\n",
    "        # Handle case where all values are the same (division by zero)\n",
    "        return np.zeros_like(metric) if isinstance(metric, np.ndarray) else 0.0000\n",
    "\n",
    "    normalized_values = (metric - min_value) / (max_value - min_value)\n",
    "    return normalized_values\n",
    "\n",
    "norm_lengths = normalize_metric(lengths)\n",
    "norm_grammar_scores = normalize_metric(grammar_scores)\n",
    "norm_fkgl_scores = normalize_metric(fkgl_scores)\n",
    "norm_gfi_scores = normalize_metric(gfi_scores)\n",
    "\n",
    "# Step 3: Print normalized metrics\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Normalized Length: {norm_lengths[i]:.4f}\")\n",
    "    print(f\"Normalized Grammar Score: {norm_grammar_scores[i]:.4f}\")\n",
    "    print(f\"Normalized FKGL Score: {norm_fkgl_scores[i]:.4f}\")\n",
    "    print(f\"Normalized GFI Score: {norm_gfi_scores[i]:.4f}\")\n",
    "\n",
    "\n",
    "# Step 4: Construct composite similarity matrix (example: simple average)\n",
    "combined_scores = (norm_lengths + norm_grammar_scores + norm_fkgl_scores + norm_gfi_scores) / 4\n",
    "combined_sim_matrix = np.outer(combined_scores, combined_scores)\n",
    "\n",
    "# Step 5: Build the graph\n",
    "G = nx.from_numpy_array(combined_sim_matrix)\n",
    "\n",
    "# Step 6: Calculate PageRank\n",
    "pagerank_scores = nx.pagerank(G, alpha=0.85, max_iter=200)\n",
    "\n",
    "# Step 7: Rank sentences based on PageRank scores\n",
    "ranked_sentences = sorted(((pagerank_scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
    "\n",
    "# Step 8: Print ranked sentences\n",
    "for score, sentence in ranked_sentences:\n",
    "    print(f\"PageRank Score: {score:.4f} - Sentence: {sentence}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}