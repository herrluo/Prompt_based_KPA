{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(arguments, key_points, labels):\n",
    "    columns = ['topic', 'premise', 'hypothesis', 'label']\n",
    "    data = []\n",
    "    for index, row in labels.iterrows():\n",
    "        argument_row = arguments.loc[arguments['arg_id'] == row['arg_id']]\n",
    "        topic = argument_row['topic'].iloc[0]\n",
    "        premise = argument_row['argument'].iloc[0]\n",
    "        kp_row = key_points.loc[key_points['key_point_id'] == row['key_point_id']]\n",
    "        hypothesis = kp_row['key_point'].iloc[0]\n",
    "        label = row['label']\n",
    "        data.append([topic, premise, hypothesis, label])\n",
    "\n",
    "    result = pd.DataFrame(data, columns=columns)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_df, tokenizer, max_length):\n",
    "        self.premises = list(text_df['premise'].values+tokenizer.sep_token+text_df['topic'].values)\n",
    "        self.hypotheses = list(text_df['hypothesis'].values+tokenizer.sep_token+text_df['topic'].values)\n",
    "        self.labels = list(text_df['label'])\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premises)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.premises[idx],\n",
    "            self.hypotheses[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KPM(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=2e-5, weight_decay=0.001):\n",
    "        super(KPM, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        outputs = self(input_ids, attention_mask, labels)\n",
    "        # print(\"--------------training-------------------------------\")\n",
    "        # print(\"Shape: \"+ str(outputs.logits.shape))\n",
    "        # print(outputs.logits)\n",
    "        self.log(\"train_loss\", torch.clone(outputs.loss).detach())\n",
    "        one_hot_labels = torch.stack([1 - labels, labels], dim=-1)\n",
    "        one_hot_labels = one_hot_labels.float()\n",
    "        # loss = outputs.loss\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs.logits, one_hot_labels, reduction='mean')\n",
    "        self.log(\"train_loss\", torch.clone(loss).detach())\n",
    "        return loss\n",
    "\n",
    "    # def on_validation_batch_start(self, batch, batch_idx, dataloader_idx):\n",
    "    #     input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "    #     print(len(input_ids))\n",
    "    #     # inputs = batch[:-1]  # Assuming the input tensor is at the first index\n",
    "    #     # print(f\"Validation Batch {batch_idx + 1}, Input Tensor Size: {inputs[0].size()}\")\n",
    "    #     # print(inputs[0])  # Assuming the input tensor is at index 0\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", torch.clone(outputs.loss).detach())\n",
    "        one_hot_labels = torch.stack([1 - labels, labels], dim=-1)\n",
    "        one_hot_labels = one_hot_labels.float()\n",
    "        # print(labels)\n",
    "        # loss = outputs.loss\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs.logits, one_hot_labels, reduction='mean')\n",
    "        self.log(\"val_loss\", torch.clone(loss).detach())\n",
    "        return  loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ArgKP2021_topics = [\n",
    "    \"Assisted suicide should be a criminal offence\",\n",
    "    \"Homeschooling should be banned\",\n",
    "    \"The vow of celibacy should be abandoned\",\n",
    "    \"We should abandon marriage\",\n",
    "    \"We should abandon the use of school uniform\",\n",
    "    \"We should abolish capital punishment\",\n",
    "    \"We should abolish intellectual property rights\",\n",
    "    \"We should abolish the right to keep and bear arms\",\n",
    "    \"We should adopt an austerity regime\",\n",
    "    \"We should adopt atheism\",\n",
    "    \"We should adopt libertarianism\",\n",
    "    \"We should ban human cloning\",\n",
    "    \"We should ban private military companies\",\n",
    "    \"We should ban the use of child actors\",\n",
    "    \"We should close Guantanamo Bay detention camp\",\n",
    "    \"We should end affirmative action\",\n",
    "    \"We should end mandatory retirement\",\n",
    "    \"We should fight for the abolition of nuclear weapons\",\n",
    "    \"We should fight urbanization\",\n",
    "    \"We should introduce compulsory voting\",\n",
    "    \"We should legalize cannabis\",\n",
    "    \"We should legalize prostitution\",\n",
    "    \"We should legalize sex selection\",\n",
    "    \"We should prohibit flag burning\",\n",
    "    \"We should prohibit women in combat\",\n",
    "    \"We should subsidize journalism\",\n",
    "    \"We should subsidize space exploration\",\n",
    "    \"We should subsidize vocational education\",\n",
    "    \"Routine child vaccinations should be mandatory\",\n",
    "    \"Social media platforms should be regulated by the government\",\n",
    "    \"The USA is a good country to live in\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We should prohibit women in combat', 'We should subsidize journalism', 'We should subsidize space exploration', 'We should subsidize vocational education']\n"
     ]
    }
   ],
   "source": [
    "dev_topics = [\n",
    "    ArgKP2021_topics[24],\n",
    "    ArgKP2021_topics[25],\n",
    "    ArgKP2021_topics[26],\n",
    "    ArgKP2021_topics[27]\n",
    "]\n",
    "print(dev_topics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# labels_df = pd.read_csv('./data/labels_train+dev.csv')\n",
    "# print(labels_df.columns)\n",
    "# argument_df = pd.read_csv('./data/arguments_train+dev.csv')\n",
    "# for index, row in labels_df.iterrows():\n",
    "#         argument_row = argument_df.loc[argument_df['arg_id'] == row['arg_id']]\n",
    "#         topic = argument_row['topic'].iloc[0]\n",
    "#         labels_df.at[index, 'topic'] = topic\n",
    "# labels_df.to_csv('./data/labels_train+dev.csv',index=False)\n",
    "# print(\"finished\")\n",
    "# labels_df= labels_df.drop(labels_df.columns[0], axis=1)\n",
    "# print(labels_df.columns)\n",
    "# labels_df.to_csv('./data/labels_train+dev.csv',index=False)\n",
    "# print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          arg_id                                           argument  \\\n",
      "5580    arg_24_0  all citizens should be given equal opportunity...   \n",
      "5581    arg_24_1  allowing women in combat gives us the numbers ...   \n",
      "5582    arg_24_2  anyone who is physically qualified should be a...   \n",
      "5583    arg_24_3  as long as women are fully trained there are m...   \n",
      "5584    arg_24_4  combat is never an individual against another ...   \n",
      "...          ...                                                ...   \n",
      "6510  arg_27_218  we should subsidize vocational education to en...   \n",
      "6511  arg_27_219  We should subsidize vocational education to su...   \n",
      "6512  arg_27_220  While many who graduate from universities stru...   \n",
      "6513  arg_27_221  with the rising cost of college tuition vocati...   \n",
      "6514  arg_27_222  yes, we should subsidize vocational education ...   \n",
      "\n",
      "                                         topic  stance  \n",
      "5580        We should prohibit women in combat      -1  \n",
      "5581        We should prohibit women in combat      -1  \n",
      "5582        We should prohibit women in combat      -1  \n",
      "5583        We should prohibit women in combat      -1  \n",
      "5584        We should prohibit women in combat      -1  \n",
      "...                                        ...     ...  \n",
      "6510  We should subsidize vocational education       1  \n",
      "6511  We should subsidize vocational education       1  \n",
      "6512  We should subsidize vocational education       1  \n",
      "6513  We should subsidize vocational education       1  \n",
      "6514  We should subsidize vocational education       1  \n",
      "\n",
      "[935 rows x 4 columns]\n",
      "          arg_id                                           argument  \\\n",
      "0        arg_0_0  `people reach their limit when it comes to the...   \n",
      "1        arg_0_1  A patient should be able to decide when they h...   \n",
      "2        arg_0_2  a person has the right to end their suffering ...   \n",
      "3        arg_0_3  a person should have the dignity to choose how...   \n",
      "4        arg_0_4  a person should have the right to be able to c...   \n",
      "...          ...                                                ...   \n",
      "5575  arg_23_212  we should prohibit flag burning because people...   \n",
      "5576  arg_23_213  we should prohibit flag burning because people...   \n",
      "5577  arg_23_214  we should prohibit flag burning because the fl...   \n",
      "5578  arg_23_215  we should prohibit flag burning for various re...   \n",
      "5579  arg_23_216  we should prohibit flag burning since it disre...   \n",
      "\n",
      "                                              topic  stance  \n",
      "0     Assisted suicide should be a criminal offence      -1  \n",
      "1     Assisted suicide should be a criminal offence      -1  \n",
      "2     Assisted suicide should be a criminal offence      -1  \n",
      "3     Assisted suicide should be a criminal offence      -1  \n",
      "4     Assisted suicide should be a criminal offence      -1  \n",
      "...                                             ...     ...  \n",
      "5575                We should prohibit flag burning       1  \n",
      "5576                We should prohibit flag burning       1  \n",
      "5577                We should prohibit flag burning       1  \n",
      "5578                We should prohibit flag burning       1  \n",
      "5579                We should prohibit flag burning       1  \n",
      "\n",
      "[5580 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "argument_df = pd.read_csv('./data/arguments_train+dev.csv')\n",
    "kp_df = pd.read_csv('./data/key_points_train+dev.csv')\n",
    "labels_df = pd.read_csv('./data/labels_train+dev.csv')\n",
    "\n",
    "\n",
    "val_argument_df = argument_df[argument_df['topic'].isin(dev_topics)]\n",
    "val_kp_df = kp_df[kp_df['topic'].isin(dev_topics)]\n",
    "val_label_df = labels_df[labels_df['topic'].isin(dev_topics)]\n",
    "val_df = preprocessing(val_argument_df, val_kp_df, val_label_df)\n",
    "print(val_argument_df)\n",
    "\n",
    "\n",
    "train_argument_df = argument_df[~argument_df.isin(val_argument_df.to_dict(orient='list')).all(1)]\n",
    "train_kp_df = kp_df[~kp_df.isin(val_kp_df.to_dict(orient='list')).all(1)]\n",
    "train_label_df = labels_df[~labels_df.isin(val_label_df.to_dict(orient='list')).all(1)]\n",
    "train_df = preprocessing(train_argument_df, train_kp_df, train_label_df)\n",
    "print(train_argument_df)\n",
    "\n",
    "test_argument_df = pd.read_csv('./data/arguments_test.csv')\n",
    "test_kp_df = pd.read_csv('./data/key_points_test.csv')\n",
    "test_label_df = pd.read_csv('./data/labels_test.csv')\n",
    "test_df = preprocessing(test_argument_df, test_kp_df, test_label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cross-encoder/nli-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CLS token present in the vocabulary? True\n",
      "Is SEP token present in the vocabulary? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "D:\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model | RobertaForSequenceClassification | 82.1 M\n",
      "-----------------------------------------------------------\n",
      "82.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.1 M    Total params\n",
      "328.480   Total estimated model params size (MB)\n",
      "D:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory ./checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60fb85df7b2a4f22a72e44697dca67e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a49804546f324cdc9dc451d3a48204f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5e163a083f94897b07e9713e2f138be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "490ddd36a5bd481da7e63460d2a24085"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b606d30ede414d63b78c46b780663f27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "296c7939f50942b68814395e8bde4e46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cross-encoder/nli-distilroberta-base\"\n",
    "num_classes = 2\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "learning_rate = 5e-05\n",
    "weight_decay = 0.001\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes = True)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# model.classifier = torch.nn.Linear(model.config.hidden_size, num_classes)\n",
    "# Change the loss function to binary cross-entropy\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Check if the \"CLS\" token is present in the vocabulary\n",
    "cls_token_present = tokenizer.cls_token in vocab\n",
    "sep_token_present = tokenizer.sep_token in vocab\n",
    "print(\"Is CLS token present in the vocabulary?\", cls_token_present)\n",
    "print(\"Is SEP token present in the vocabulary?\", sep_token_present)\n",
    "\n",
    "train_dataset = Dataset(train_df, tokenizer, max_length)\n",
    "val_dataset = Dataset(val_df, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = KPM(model, learning_rate)\n",
    "\n",
    "# Define a ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./checkpoint',\n",
    "    filename='nli_model-{epoch:02d}-{val_loss:.2f}-24_25_26_27',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping =EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    min_epochs = 0, # change this\n",
    "    max_epochs = 20,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    accelerator=\"auto\",\n",
    "    #progress_bar_refresh_rate=30,\n",
    "    #gpus = 1 if device.type == 'cuda' else 0\n",
    "    devices = 1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# start training\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "print(\"Training is finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming you have already trained the model and saved a checkpoint\n",
    "checkpoint_path = './checkpoint/nli_model-epoch=01-val_loss=0.37.ckpt'\n",
    "# Load the model from the checkpoint\n",
    "model_name = \"cross-encoder/nli-distilroberta-base\"\n",
    "num_classes = 2\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "learning_rate = 5e-05\n",
    "weight_decay = 0.001\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes = True)\n",
    "loaded_model = KPM.load_from_checkpoint(model=model, checkpoint_path=checkpoint_path)\n",
    "print(\"hello world\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "test_dataset = Dataset(test_df, tokenizer, max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Make predictions on the test set with probabilities\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids, attention_mask = batch['input_ids'], batch['attention_mask']\n",
    "        outputs = loaded_model(input_ids, attention_mask)\n",
    "        logits = outputs.logits\n",
    "        # print(logits)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        predictions = torch.argmax(logits, dim=1).tolist()\n",
    "        # print(predictions)\n",
    "        print(probabilities)\n",
    "        all_predictions.extend(predictions)\n",
    "        all_probabilities.extend(probabilities.tolist())\n",
    "\n",
    "\n",
    "print(all_predictions)\n",
    "print(all_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(all_predictions))\n",
    "print(len(all_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8513832688331604, 0.9530447125434875, 0.9813437461853027, 0.9999032020568848, 0.9502105712890625, 0.9856218695640564, 0.9996399879455566, 0.7003836631774902, 0.9784537553787231, 0.9999059438705444, 0.5496004223823547, 0.9834389090538025, 0.9875774383544922, 0.9435656070709229, 0.9999083280563354, 0.8970844745635986, 0.9932764768600464, 0.5377925038337708, 0.9752899408340454, 0.9779468178749084, 0.9998916387557983, 0.6552639603614807, 0.9617480635643005, 0.9989585876464844, 0.9997628331184387, 0.9690905809402466, 0.7799464464187622, 0.9968823194503784, 0.9996205568313599, 0.7533658742904663, 0.9707180857658386, 0.9991835951805115, 0.9999151229858398, 0.6591960191726685, 0.9929141998291016, 0.6223980188369751, 0.5727285146713257, 0.9057391285896301, 0.9987348914146423, 0.6909785270690918, 0.9980675578117371, 0.9997209906578064, 0.99972003698349, 0.9550588130950928, 0.7782137989997864, 0.5976061224937439, 0.9899438619613647, 0.6962425112724304, 0.7719510197639465, 0.811423122882843, 0.8992534875869751, 0.5972216129302979, 0.6113153100013733, 0.9486123919487, 0.9899789094924927, 0.9902742505073547, 0.748446524143219, 0.6522065997123718, 0.9666641354560852, 0.9774086475372314, 0.8282991647720337, 0.997252881526947, 0.974445641040802, 0.9931746125221252, 0.7029930949211121, 0.9592380523681641, 0.9439685940742493, 0.7721773982048035, 0.7258421778678894, 0.7839317321777344, 0.9823049306869507, 0.6100481152534485, 0.9611214995384216, 0.9941228032112122, 0.9978960752487183, 0.9998898506164551, 0.9693785905838013, 0.9064202904701233, 0.9997166991233826, 0.9716830849647522, 0.9994150400161743, 0.9847890138626099, 0.9482450485229492, 0.9998831748962402, 0.9733183979988098, 0.9681566953659058, 0.9202513098716736, 0.5423319935798645, 0.9998997449874878, 0.9998822212219238, 0.9995612502098083, 0.9457176327705383, 0.9609208106994629, 0.9994470477104187, 0.7914904356002808, 0.9998682737350464, 0.6563959717750549, 0.5982317924499512, 0.9894424676895142, 0.9676223993301392, 0.8933056592941284, 0.9760515689849854, 0.9988586902618408, 0.9996514320373535, 0.9985879063606262, 0.999864935874939, 0.9981538653373718, 0.975978672504425, 0.9951382279396057, 0.8931299448013306, 0.9968053102493286, 0.8430793285369873, 0.9965947270393372, 0.7779294848442078, 0.5263563990592957, 0.9995717406272888, 0.8514848351478577, 0.6157976984977722, 0.9990789890289307, 0.7699733376502991, 0.5020124316215515, 0.9639413356781006, 0.7042561769485474, 0.994597315788269, 0.9015599489212036, 0.9998949766159058, 0.954387366771698, 0.999870777130127, 0.9853155612945557, 0.9664434194564819, 0.9998985528945923, 0.9871788024902344, 0.9998904466629028, 0.978142499923706, 0.9997794032096863, 0.9782586693763733, 0.9999047517776489, 0.9916111826896667, 0.9973347783088684, 0.9998952150344849, 0.9838058948516846, 0.9993519186973572, 0.9973980188369751, 0.980678915977478, 0.999841570854187, 0.9585533142089844, 0.5291685461997986, 0.9999029636383057, 0.9997649788856506, 0.9999237060546875, 0.7492840886116028, 0.9994680285453796, 0.9998375177383423, 0.969867467880249, 0.9980331063270569, 0.7566134333610535, 0.5871942639350891, 0.8916779160499573, 0.999006450176239, 0.9996562004089355, 0.771586537361145, 0.9998494386672974, 0.9048117995262146, 0.9905776977539062, 0.9902674555778503, 0.9988287091255188, 0.9998713731765747, 0.9876082539558411, 0.6316632032394409, 0.9998989105224609, 0.9127901196479797, 0.9947291016578674, 0.9999027252197266, 0.952410101890564, 0.9998180270195007, 0.9997181296348572, 0.7919324636459351, 0.711300253868103, 0.999889612197876, 0.9551475048065186, 0.6076022982597351, 0.9934218525886536, 0.8183877468109131, 0.9998353719711304, 0.7370015978813171, 0.8771929144859314, 0.8787522912025452, 0.999903678894043, 0.9380733966827393, 0.9782479405403137, 0.6080690622329712, 0.9997621178627014, 0.9912857413291931, 0.9996728897094727, 0.9991679191589355, 0.9641919732093811, 0.9997368454933167, 0.9605310559272766, 0.9987977743148804, 0.9975850582122803, 0.9991980195045471, 0.6792312264442444, 0.9199085831642151, 0.9998573064804077, 0.9999397993087769, 0.9480989575386047, 0.9998781681060791, 0.9983962178230286, 0.9989166259765625, 0.9964726567268372, 0.7922261953353882, 0.9999083280563354, 0.9997267127037048, 0.9998607635498047, 0.8745146989822388, 0.999855637550354, 0.9998860359191895, 0.9841025471687317, 0.8915327191352844, 0.9994595646858215, 0.9932900667190552, 0.8275302648544312, 0.6829186081886292, 0.9142369627952576, 0.9943016767501831, 0.8014311790466309, 0.986972987651825, 0.8168166279792786, 0.7319121956825256, 0.9986849427223206, 0.9955604076385498, 0.9925547242164612, 0.9997743964195251, 0.5737032294273376, 0.9989932179450989, 0.9962536096572876, 0.9978510141372681, 0.5161433815956116, 0.9998477697372437, 0.5427618622779846, 0.6879714727401733, 0.609595537185669, 0.6611960530281067, 0.8734541535377502, 0.8427631258964539, 0.9995900988578796, 0.9997187256813049, 0.9134142398834229, 0.8662251830101013, 0.7394587993621826, 0.709061324596405, 0.6325216889381409, 0.9828526377677917, 0.9058528542518616, 0.5638460516929626, 0.671071469783783, 0.8890025019645691, 0.9253787398338318, 0.6988968253135681, 0.9998805522918701, 0.7778494954109192, 0.9982749223709106, 0.9994303584098816, 0.5245633721351624, 0.5036904811859131, 0.557733416557312, 0.5492929816246033, 0.9430997371673584, 0.7818096280097961, 0.5911322236061096, 0.7547577023506165, 0.6111242771148682, 0.7483951449394226, 0.5143530964851379, 0.9635242819786072, 0.9726420640945435, 0.9994649291038513, 0.9999326467514038, 0.5478954315185547, 0.8250795006752014, 0.9787924885749817, 0.6146439909934998, 0.5813345909118652, 0.5618897676467896, 0.5734644532203674, 0.8127045631408691, 0.9490034580230713, 0.9953984618186951, 0.958132803440094, 0.9538486003875732, 0.9980687499046326, 0.9995928406715393, 0.8598976135253906, 0.825182318687439, 0.9340054988861084, 0.824336051940918, 0.5290191769599915, 0.9146896600723267, 0.9790904521942139, 0.9904581308364868, 0.9974849224090576, 0.6046001315116882, 0.9967417120933533, 0.9957568049430847, 0.7088556289672852, 0.9958081245422363, 0.9988293051719666, 0.9490408301353455, 0.9943423271179199, 0.994522213935852, 0.8266891241073608, 0.8515735864639282, 0.9944432377815247, 0.9974650144577026, 0.9977858066558838, 0.9996464252471924, 0.7925766110420227, 0.9996670484542847, 0.9897144436836243, 0.9348388314247131, 0.922114372253418, 0.9117437601089478, 0.8782379031181335, 0.9800764918327332, 0.9863392114639282, 0.999514102935791, 0.9998270869255066, 0.9279208779335022, 0.9998760223388672, 0.9707396626472473, 0.5217549800872803, 0.9992884397506714, 0.9469262957572937, 0.9996752738952637, 0.98899906873703, 0.9861370325088501, 0.9953969120979309, 0.9630313515663147, 0.543485701084137, 0.9478558897972107, 0.8294611573219299, 0.5940374135971069, 0.5795333385467529, 0.8218989372253418, 0.9064396023750305, 0.9327378869056702, 0.5171522498130798, 0.9158706665039062, 0.9955177903175354, 0.803199827671051, 0.9993439316749573, 0.9108673930168152, 0.989391028881073, 0.9000037908554077, 0.9781891703605652, 0.7967236638069153, 0.9860811233520508, 0.9955015778541565, 0.6835829615592957, 0.7826042175292969, 0.6942452192306519, 0.9565573334693909, 0.6393011808395386, 0.7624756693840027, 0.8243324160575867, 0.9284123182296753, 0.9694671034812927, 0.9106485247612, 0.9662832021713257, 0.9872691631317139, 0.8317134976387024, 0.9969832301139832, 0.8047659397125244, 0.6750153303146362, 0.9557937383651733, 0.9242368340492249, 0.9970588684082031, 0.6113156676292419, 0.5322919487953186, 0.9477708339691162, 0.9446662664413452, 0.7404581308364868, 0.5060555934906006, 0.6148340106010437, 0.9532967209815979, 0.9944062232971191, 0.9993945360183716, 0.9976535439491272, 0.8255547285079956, 0.9683436155319214, 0.9995425939559937, 0.8262607455253601, 0.9997738003730774, 0.6821354031562805, 0.9998818635940552, 0.999947190284729, 0.9200083017349243, 0.9973969459533691, 0.9961680769920349, 0.9762012958526611, 0.919858455657959, 0.8829113841056824, 0.5275248289108276, 0.9867979884147644, 0.9935528039932251, 0.9977697134017944, 0.9987288117408752, 0.9994522929191589, 0.9880186319351196, 0.868056058883667, 0.9491918087005615, 0.5704634189605713, 0.9067488312721252, 0.9206315875053406, 0.6440744400024414, 0.9924962520599365, 0.998457670211792, 0.998141884803772, 0.9986761212348938, 0.9930341243743896, 0.8544672131538391, 0.7338864207267761, 0.9952253103256226, 0.9947090148925781, 0.9871757626533508, 0.998214602470398, 0.597841739654541, 0.6606065630912781, 0.9114151000976562, 0.5160775184631348, 0.6196350455284119, 0.7188560962677002, 0.9964800477027893, 0.9987589120864868, 0.9353139400482178, 0.769615650177002, 0.9979573488235474, 0.999895453453064, 0.9972508549690247, 0.99982750415802, 0.99945467710495, 0.9998206496238708, 0.9998490810394287, 0.5114713907241821, 0.999821126461029, 0.99980229139328, 0.9997754693031311, 0.5664029121398926, 0.9996837377548218, 0.9997712969779968, 0.9998316764831543, 0.9789460301399231, 0.9599992632865906, 0.9969093203544617, 0.6932920813560486, 0.9986316561698914, 0.9555683732032776, 0.8419002294540405, 0.880025327205658, 0.8857693076133728, 0.9969210624694824, 0.9898285865783691, 0.9720970988273621, 0.9804546236991882, 0.9876635670661926, 0.6329707503318787, 0.8042886257171631, 0.8967093229293823, 0.9129850268363953, 0.8071039319038391, 0.9823922514915466, 0.5218459963798523, 0.996462881565094, 0.896249532699585, 0.9991938471794128, 0.9162976741790771, 0.9985973238945007, 0.9998089671134949, 0.9941955208778381, 0.9849367737770081, 0.9998534917831421, 0.999723494052887, 0.9914705157279968, 0.5911514163017273, 0.5068038702011108, 0.9949671626091003, 0.9920104742050171, 0.9674618244171143, 0.9816834926605225, 0.9900742173194885, 0.5679484605789185, 0.9722926020622253, 0.9734626412391663, 0.9813128709793091, 0.833772599697113, 0.7074090242385864, 0.6761221885681152, 0.987894594669342, 0.738551139831543, 0.9679126143455505, 0.9985301494598389, 0.9486311674118042, 0.9999024868011475, 0.5997301340103149, 0.7672325968742371, 0.8550766706466675, 0.9923444390296936, 0.9862854480743408, 0.9558120369911194, 0.7399235367774963, 0.9738329648971558, 0.9689868092536926, 0.8446101546287537, 0.9992642998695374, 0.9976691603660583, 0.966937780380249, 0.9955938458442688, 0.9973065853118896, 0.9978840947151184, 0.9905548691749573, 0.9819301962852478, 0.844569981098175, 0.9689712524414062, 0.8851091861724854, 0.891783595085144, 0.877269983291626, 0.9529958963394165, 0.76735520362854, 0.9998769760131836, 0.997387707233429, 0.9289748668670654, 0.9671266674995422, 0.9006006717681885, 0.787129819393158, 0.641959011554718, 0.6595974564552307, 0.7724335789680481, 0.5412322878837585, 0.9657436609268188, 0.6171104311943054, 0.9576694369316101, 0.7257216572761536, 0.5230569839477539, 0.961747407913208, 0.8319189548492432, 0.9636247754096985, 0.9886670112609863, 0.994625985622406, 0.5090951919555664, 0.9959241151809692, 0.8615594506263733, 0.8775131702423096, 0.9833036661148071, 0.9524178504943848, 0.77475506067276, 0.9681566953659058, 0.9746228456497192, 0.7350395321846008, 0.5759754776954651, 0.7438004016876221, 0.6332107782363892, 0.8416620492935181, 0.543776273727417, 0.9926567673683167, 0.8061956763267517, 0.8020919561386108, 0.9434031844139099, 0.7298478484153748, 0.5947983860969543, 0.5706536173820496, 0.9997773766517639, 0.5287935733795166, 0.9363329410552979, 0.8684743642807007, 0.6679208874702454, 0.6028931140899658, 0.893221914768219, 0.9977325201034546, 0.8354016542434692, 0.546332061290741, 0.788733184337616, 0.5926570892333984, 0.9900950193405151, 0.8587503433227539, 0.8392343521118164, 0.8806257247924805, 0.9775107502937317, 0.8366393446922302, 0.6999241709709167, 0.835357129573822, 0.8600831031799316, 0.809673547744751, 0.7755870223045349, 0.8940685391426086, 0.8642890453338623, 0.9923417568206787, 0.7179439067840576, 0.5411581993103027, 0.7956202030181885, 0.6886364817619324, 0.9881592988967896, 0.7270752787590027, 0.8176929354667664, 0.9992930889129639, 0.7642838358879089, 0.9983702301979065, 0.7867724299430847, 0.9997385144233704, 0.5544752478599548, 0.9995139837265015, 0.9976721405982971, 0.9995254278182983, 0.51087486743927, 0.9996742010116577, 0.9973360896110535, 0.9992515444755554, 0.9993782043457031, 0.9999196529388428, 0.9993104934692383, 0.9097200632095337, 0.8862556219100952, 0.7328336238861084, 0.7633282542228699, 0.9712520837783813, 0.9063338041305542, 0.9995884299278259, 0.9946145415306091, 0.9126708507537842, 0.9940668344497681, 0.8391499519348145, 0.9326478838920593, 0.9738348722457886, 0.8965049982070923, 0.8642448782920837, 0.9468405842781067, 0.9844014048576355, 0.9628798365592957, 0.9913461804389954, 0.9997183680534363, 0.9999220371246338, 0.6614550352096558, 0.8803691267967224, 0.998012900352478, 0.9988521337509155, 0.783142626285553, 0.6954634189605713, 0.9701729416847229, 0.9201715588569641, 0.657334566116333, 0.6384669542312622, 0.9763009548187256, 0.5812151432037354, 0.6021416783332825, 0.964204728603363, 0.9535558223724365, 0.7654501795768738, 0.8375113010406494, 0.8908610939979553, 0.517733633518219, 0.9479049444198608, 0.7039787769317627, 0.960870087146759, 0.9948272109031677, 0.9358130693435669, 0.5937225222587585, 0.9545913338661194, 0.9701322913169861, 0.8988790512084961, 0.8651304841041565, 0.866082489490509, 0.833204984664917, 0.9508710503578186, 0.98271644115448, 0.9644031524658203, 0.8236976861953735, 0.9786215424537659, 0.9158535599708557, 0.9996507167816162, 0.9988565444946289, 0.9999098777770996, 0.907871663570404, 0.9999066591262817, 0.9862924814224243, 0.8482807278633118, 0.9998959302902222, 0.8636375069618225, 0.9321969151496887, 0.7257874608039856, 0.917109489440918, 0.8842817544937134, 0.589961588382721, 0.8544718027114868, 0.9782596826553345, 0.9247324466705322, 0.778457760810852, 0.9627329707145691, 0.9495916366577148, 0.7412391304969788, 0.9926615953445435, 0.8896539807319641, 0.9936020970344543, 0.7679986357688904, 0.8421513438224792, 0.7350776791572571, 0.5397281646728516, 0.7511036396026611, 0.9058883786201477, 0.958962082862854, 0.9934697151184082, 0.9988516569137573, 0.7319207787513733, 0.9997970461845398, 0.5653168559074402, 0.9998282194137573, 0.9997316002845764, 0.8671370148658752, 0.908090353012085, 0.9348262548446655, 0.999201238155365, 0.9037600755691528, 0.5040416121482849, 0.8298083543777466, 0.5988480448722839, 0.670225977897644, 0.7652238607406616, 0.6902949213981628, 0.7710279226303101, 0.9738011956214905, 0.8485504984855652, 0.9998579025268555, 0.9999516010284424, 0.996316134929657, 0.9981434345245361, 0.9829457998275757, 0.8686462640762329, 0.9584078192710876, 0.9738392233848572, 0.95720374584198, 0.8970648646354675, 0.9612189531326294, 0.9715747237205505, 0.9864829182624817, 0.9374058842658997, 0.9978567957878113, 0.993450403213501, 0.9526355862617493, 0.8956825137138367, 0.9968293309211731, 0.9999072551727295, 0.9868956208229065, 0.994765043258667, 0.9992339611053467, 0.9702231884002686, 0.9922771453857422, 0.9915772676467896, 0.9995737671852112, 0.9999085664749146, 0.9891127943992615, 0.9991414546966553, 0.6584577560424805, 0.8895299434661865, 0.7291731834411621, 0.9981702566146851, 0.8833160400390625, 0.7662602066993713, 0.9865168333053589, 0.9341003894805908, 0.9261837005615234, 0.8646911978721619, 0.5711892247200012, 0.9646767377853394, 0.6003857851028442, 0.5378522276878357, 0.9670923352241516, 0.9838268160820007, 0.5626123547554016, 0.9260124564170837, 0.9250842928886414, 0.8767720460891724, 0.9680581092834473, 0.8546494245529175, 0.9685487151145935, 0.9976246953010559, 0.859915018081665, 0.9877324104309082, 0.9941622614860535, 0.7963650226593018, 0.9022074937820435, 0.8399057984352112, 0.9482495188713074, 0.9941257238388062, 0.999552309513092, 0.9997135996818542, 0.6718184947967529, 0.9995540976524353, 0.9998656511306763, 0.9888091683387756, 0.5714634656906128, 0.995891809463501, 0.9995386600494385, 0.9997913241386414, 0.965626060962677, 0.9995012283325195, 0.9998194575309753, 0.8370341658592224, 0.9998518228530884, 0.9955047965049744, 0.9997978806495667, 0.9993981122970581, 0.987524151802063, 0.9903646111488342, 0.9997350573539734, 0.9968781471252441, 0.6141829490661621, 0.7333463430404663, 0.9991349577903748, 0.9995668530464172, 0.918157160282135, 0.9998272061347961, 0.9867764115333557, 0.9973502159118652, 0.9691532850265503, 0.9985488057136536, 0.5795518755912781, 0.984329342842102, 0.9903518557548523, 0.556800901889801, 0.9988766312599182, 0.5524758100509644, 0.9909713268280029, 0.7214275598526001, 0.9737693071365356, 0.9995744824409485, 0.7334328293800354, 0.9929783940315247, 0.9714356064796448, 0.9746666550636292, 0.9951900243759155, 0.8988023996353149, 0.7030220627784729, 0.9795563220977783, 0.6761339902877808, 0.9996304512023926, 0.8682393431663513, 0.8933880925178528, 0.8016486763954163, 0.7101985216140747, 0.8389045000076294, 0.9997414946556091, 0.9996547698974609, 0.8179163932800293, 0.5340718626976013, 0.929477334022522, 0.6450963020324707, 0.5338085293769836, 0.5455807447433472, 0.7557594776153564, 0.8531678318977356, 0.9948989748954773, 0.5641182661056519, 0.9921741485595703, 0.9940776824951172, 0.9075148701667786, 0.9660401940345764, 0.9293477535247803, 0.6125682592391968, 0.5262430906295776, 0.9428786039352417, 0.7947667241096497, 0.8128925561904907, 0.935569167137146, 0.5930061340332031, 0.6213266253471375, 0.6575527191162109, 0.5641980171203613, 0.5926319360733032, 0.9793973565101624, 0.9689971208572388, 0.9989697933197021, 0.9993247985839844, 0.9998331069946289, 0.8657304048538208, 0.9999041557312012, 0.5226322412490845, 0.9776776432991028, 0.9899032115936279, 0.9994373917579651, 0.9988515377044678, 0.9997692704200745, 0.7853257656097412, 0.5449771285057068, 0.9925792813301086, 0.908612847328186, 0.8822534680366516, 0.9935010075569153, 0.9988357424736023, 0.9989792704582214, 0.9942135214805603, 0.9937291145324707, 0.9355129599571228, 0.8617033362388611, 0.8874141573905945, 0.6363013386726379, 0.6330729722976685, 0.9268527626991272, 0.8946950435638428, 0.7191468477249146, 0.9218747019767761, 0.9337344765663147, 0.6146575808525085, 0.898902952671051, 0.8482436537742615, 0.5775225162506104, 0.8883681297302246, 0.9996213912963867, 0.99982750415802, 0.9823583960533142, 0.6230810880661011, 0.9970189332962036, 0.9226862192153931, 0.9060065746307373, 0.9640489220619202, 0.9993461966514587, 0.9996767044067383, 0.7387956976890564, 0.9998345375061035, 0.9998331069946289, 0.6736886501312256, 0.9956629872322083, 0.9983466863632202, 0.7926768064498901, 0.9998867511749268, 0.9935551285743713, 0.9945905208587646, 0.9300800561904907, 0.9975530505180359, 0.9416186809539795, 0.8595029711723328, 0.9945231676101685, 0.7383207082748413, 0.8447259068489075, 0.9986262321472168, 0.9926048517227173, 0.9656798839569092, 0.9845134615898132, 0.99700528383255, 0.9876555800437927, 0.9162363409996033, 0.9484772682189941, 0.8508405685424805, 0.875810980796814, 0.8384447693824768, 0.9928483963012695, 0.9891190528869629, 0.9983431100845337, 0.5211345553398132, 0.7831568717956543, 0.6604401469230652, 0.9906022548675537, 0.8241971135139465, 0.816200315952301, 0.6412611603736877, 0.7987078428268433, 0.9843763113021851, 0.6036192178726196, 0.9826906323432922, 0.9983925223350525, 0.9960263967514038, 0.9782548546791077, 0.9815111756324768, 0.9902230501174927, 0.5250669717788696, 0.9995052814483643, 0.591419517993927, 0.9982655644416809, 0.8298705816268921, 0.6707179546356201, 0.569244384765625, 0.9917559623718262, 0.5081207156181335, 0.958972156047821, 0.9410704374313354, 0.8247047662734985, 0.8478012084960938, 0.8780102133750916, 0.8037700653076172, 0.547145426273346, 0.9858723282814026, 0.885103166103363, 0.9435688257217407, 0.9984639883041382, 0.7240653038024902, 0.9884865283966064, 0.9996520280838013, 0.9986156225204468, 0.834088146686554, 0.9429747462272644, 0.9317839741706848, 0.7145373225212097, 0.999792754650116, 0.9999054670333862, 0.9094762802124023, 0.9998051524162292, 0.7864990234375, 0.6206504106521606, 0.8369038105010986, 0.6259471774101257, 0.9168417453765869, 0.8900653719902039, 0.8643679618835449, 0.9997678399085999, 0.9828357100486755, 0.9713427424430847, 0.9793440699577332, 0.9893760681152344, 0.9157968759536743, 0.9998880624771118, 0.7800464630126953, 0.9764759540557861, 0.744618833065033, 0.9999065399169922, 0.9297650456428528, 0.7826593518257141, 0.8679641485214233, 0.9949328303337097, 0.8811341524124146, 0.9767063856124878, 0.8287244439125061, 0.9979696869850159, 0.9992523789405823, 0.8866685628890991, 0.9966842532157898, 0.9924578666687012, 0.9981141090393066, 0.9992044568061829, 0.8162255883216858, 0.9997209906578064, 0.9038681983947754, 0.9667965173721313, 0.9965224266052246, 0.9958522319793701, 0.8723572492599487, 0.6739976406097412, 0.9990033507347107, 0.9965078234672546, 0.921307384967804, 0.9998511075973511, 0.993119478225708, 0.9033092856407166, 0.9998953342437744, 0.6740580797195435, 0.9974472522735596, 0.9864861965179443, 0.8913915753364563, 0.8550719618797302, 0.9545140266418457, 0.9770853519439697, 0.9999030828475952, 0.8239752650260925, 0.9973850846290588, 0.7265297770500183, 0.936809241771698, 0.9976790547370911, 0.7220010161399841, 0.940201997756958, 0.9495372176170349, 0.9999045133590698, 0.8436360955238342, 0.9117459654808044, 0.9975213408470154, 0.6610763669013977, 0.9547353982925415, 0.9858585000038147, 0.9874898791313171, 0.9971283078193665, 0.9981796741485596, 0.8943251371383667, 0.7250198721885681, 0.6619277596473694, 0.999901533126831, 0.9997122883796692, 0.9998314380645752, 0.9797734618186951, 0.6671554446220398, 0.6145946979522705, 0.9616953730583191, 0.5144726634025574, 0.9812553524971008, 0.9193344712257385, 0.671636164188385, 0.9898179173469543, 0.9545565843582153, 0.9997337460517883, 0.8385178446769714, 0.7307582497596741, 0.9946489930152893, 0.9057788252830505, 0.9981508851051331, 0.9980097413063049, 0.9939324259757996, 0.9998983144760132, 0.9972895383834839, 0.9941721558570862, 0.9550211429595947, 0.9983421564102173, 0.9980674386024475, 0.7215639352798462, 0.986724853515625, 0.8749432563781738, 0.9841408729553223, 0.8761109113693237, 0.9478959441184998, 0.8717118501663208, 0.9482096433639526, 0.9992165565490723, 0.951483964920044, 0.999178946018219, 0.9997664093971252, 0.9746187329292297, 0.9998829364776611, 0.9899868369102478, 0.9939321875572205, 0.9989256262779236, 0.9993359446525574, 0.9996578693389893, 0.7056188583374023, 0.9990905523300171, 0.9970937967300415, 0.9945898056030273, 0.9745110869407654, 0.9840706586837769, 0.9865146279335022, 0.6746056079864502, 0.9429581165313721, 0.9687050580978394, 0.9453288316726685, 0.9554274082183838, 0.56910240650177, 0.6683382391929626, 0.9597432613372803, 0.9054747819900513, 0.8758041262626648, 0.9156599640846252, 0.809048593044281, 0.9956522583961487, 0.8129132390022278, 0.9998563528060913, 0.9937217831611633, 0.8677172660827637, 0.9102526307106018, 0.5544623136520386, 0.5523930788040161, 0.8726171851158142, 0.7045442461967468, 0.999649167060852, 0.5567849278450012, 0.7729811072349548, 0.87859046459198, 0.9930729269981384, 0.683892548084259, 0.9959873557090759, 0.9998754262924194, 0.9457820057868958, 0.9495082497596741, 0.5911976099014282, 0.9865378141403198, 0.9997939467430115, 0.9686567187309265, 0.6263865828514099, 0.556095540523529, 0.9939414262771606, 0.7932080030441284, 0.8670144081115723, 0.5664807558059692, 0.9734920263290405, 0.9941480159759521, 0.8492625951766968, 0.8507402539253235, 0.9937664270401001, 0.9996819496154785, 0.5023633241653442, 0.9999034404754639, 0.9130101799964905, 0.999134361743927, 0.9992918968200684, 0.8995137810707092, 0.9998792409896851, 0.9947315454483032, 0.8875837326049805, 0.9866791367530823, 0.8404811024665833, 0.5725207328796387, 0.7709400057792664, 0.9988138675689697, 0.5960090756416321, 0.6088050603866577, 0.8958938717842102, 0.7336485385894775, 0.8802738189697266, 0.9878742098808289, 0.9884474873542786, 0.9980720281600952, 0.9527186751365662, 0.9915348291397095, 0.9993452429771423, 0.6181235313415527, 0.8642377853393555, 0.947187066078186, 0.999370276927948, 0.8727058172225952, 0.6995563507080078, 0.9488217234611511, 0.9691652655601501, 0.820491373538971, 0.6159275770187378, 0.8826611638069153, 0.9970055222511292, 0.6214826703071594, 0.8853106498718262, 0.9943420886993408, 0.8249354958534241, 0.9970297813415527, 0.6255261301994324, 0.9990668892860413, 0.9805395603179932, 0.9973948001861572, 0.9998250603675842, 0.6251735091209412, 0.999649167060852, 0.5397639274597168, 0.9990280866622925, 0.5411494374275208, 0.6944525837898254, 0.5573371648788452, 0.6789320111274719, 0.5940443277359009, 0.6755496263504028, 0.7178205847740173, 0.8602896928787231, 0.9986415505409241, 0.852811872959137, 0.9189696907997131, 0.9974488615989685, 0.9971047043800354, 0.9181615114212036, 0.8171990513801575, 0.9992187023162842, 0.9987117052078247, 0.9437116980552673, 0.8123030662536621, 0.9988483190536499, 0.9561173915863037, 0.7173996567726135, 0.7675840258598328, 0.9997395873069763, 0.6184726357460022, 0.9228724837303162, 0.7853261828422546, 0.9937211275100708, 0.6252683997154236, 0.7037097811698914, 0.9810302257537842, 0.6212766170501709, 0.9962124824523926, 0.845970094203949, 0.9012121558189392, 0.6937204599380493, 0.9934146404266357, 0.8613928556442261, 0.7926709651947021, 0.988976240158081, 0.749021589756012, 0.5325580835342407, 0.887627899646759, 0.5895577073097229, 0.530483067035675, 0.9914751052856445, 0.7924109101295471, 0.8777907490730286, 0.9995933175086975, 0.5948665738105774, 0.9966938495635986, 0.7388184070587158, 0.8839712738990784, 0.998941957950592, 0.9971274733543396, 0.9161092638969421, 0.9091646075248718, 0.9346804022789001, 0.99715256690979, 0.6937610507011414, 0.9227848649024963, 0.7317734956741333, 0.9970605969429016, 0.8462323546409607, 0.7950872182846069, 0.9843599200248718, 0.615648627281189, 0.9629296660423279, 0.9542176127433777, 0.8704125881195068, 0.7274447679519653, 0.9992241859436035, 0.7496234774589539, 0.8250848650932312, 0.5767925381660461, 0.9400497078895569, 0.936171293258667, 0.6115437746047974, 0.7489535808563232, 0.9740003347396851, 0.9841614961624146, 0.9849430322647095, 0.9819066524505615, 0.8084098100662231, 0.9202984571456909, 0.8453516364097595, 0.6703757643699646, 0.967620849609375, 0.9979953765869141, 0.9999141693115234, 0.9300598502159119, 0.9990975856781006, 0.7125037312507629, 0.9429622292518616, 0.574192225933075, 0.8079161047935486, 0.9312000870704651, 0.9587161540985107, 0.9892868995666504, 0.9918478727340698, 0.8356683254241943, 0.9607886075973511, 0.9495176672935486, 0.7160811424255371, 0.8641732335090637, 0.5665396451950073, 0.9985628724098206, 0.9998868703842163, 0.7684958577156067, 0.9993765950202942, 0.7717361450195312, 0.9920884370803833, 0.9947717785835266, 0.9998763799667358, 0.9893509745597839, 0.6323463320732117, 0.5867719650268555, 0.811152458190918, 0.9698584079742432, 0.8001869916915894, 0.8706669807434082, 0.8694427609443665, 0.639366865158081, 0.6352425813674927, 0.9930985569953918, 0.9845150709152222, 0.99918133020401, 0.911083996295929, 0.8837952613830566, 0.5709035396575928, 0.5830399394035339, 0.9943413734436035, 0.7778394222259521, 0.8857182860374451, 0.7054546475410461, 0.953477680683136, 0.9751384258270264, 0.9850971102714539, 0.9520871043205261, 0.9301809668540955, 0.709171712398529, 0.8034195303916931, 0.9972821474075317, 0.9991856217384338, 0.5165082812309265, 0.9998693466186523, 0.5015056729316711, 0.976783037185669, 0.9969865679740906, 0.9234501123428345, 0.9559615850448608, 0.8967047333717346, 0.9992523789405823, 0.725231409072876, 0.9349709749221802, 0.7065419554710388, 0.9989344477653503, 0.5267675518989563, 0.9467129707336426, 0.5302206873893738, 0.9891696572303772, 0.540772020816803, 0.863486111164093, 0.9347503185272217, 0.8725550174713135, 0.9970269799232483, 0.9986166954040527, 0.7991779446601868, 0.9995686411857605, 0.9471443891525269, 0.9960829019546509, 0.9998767375946045, 0.8112508654594421, 0.9998619556427002, 0.9312321543693542, 0.9938549399375916, 0.6507406830787659, 0.5554109215736389, 0.9220495820045471, 0.9949656128883362, 0.5349953174591064, 0.9700047373771667, 0.8433296084403992, 0.9786965847015381, 0.5527569651603699, 0.647299587726593, 0.9663761854171753, 0.7636376619338989, 0.9982166886329651, 0.7869056463241577, 0.9929325580596924, 0.9028876423835754, 0.993385374546051, 0.8732137084007263, 0.8209962248802185, 0.98954176902771, 0.8999673128128052, 0.9785520434379578, 0.8978112936019897, 0.8943536281585693, 0.9948441982269287, 0.9043546915054321, 0.994617760181427, 0.6600733995437622, 0.8654658198356628, 0.9951906204223633, 0.8326038122177124, 0.9118201732635498, 0.6444182991981506, 0.5516105890274048, 0.9911504983901978, 0.6019943952560425, 0.6461093425750732, 0.598193347454071, 0.7526971101760864, 0.6561618447303772, 0.7785884141921997, 0.5381491184234619, 0.9525452852249146, 0.9876402020454407, 0.9698817133903503, 0.7064176797866821, 0.5876316428184509, 0.7058622241020203, 0.9879163503646851, 0.9997250437736511, 0.999901533126831, 0.9998615980148315, 0.6661838293075562, 0.8300884366035461, 0.5365763902664185, 0.9050092101097107, 0.999135434627533, 0.970379650592804, 0.9989109039306641, 0.9574216604232788, 0.9694124460220337, 0.6555721163749695, 0.9920616149902344, 0.5651113986968994, 0.516021192073822, 0.7764427065849304, 0.5198609828948975, 0.6583099961280823, 0.7381277084350586, 0.915857195854187, 0.7424654960632324, 0.9797580242156982, 0.9965384006500244, 0.5551350116729736, 0.7623058557510376, 0.7369272708892822, 0.7651714086532593, 0.7829843163490295, 0.9842236638069153, 0.9985635876655579, 0.9999014139175415, 0.7986815571784973, 0.6787272095680237, 0.9958621263504028, 0.9985779523849487, 0.9442300796508789, 0.9910506010055542, 0.9998235106468201, 0.982853889465332, 0.999672532081604, 0.7402641773223877, 0.7346073985099792, 0.7416911721229553, 0.7538138031959534, 0.8756545782089233, 0.7523985505104065, 0.8656308054924011, 0.6950079202651978, 0.9022170901298523, 0.7791194319725037, 0.661482572555542, 0.6541414260864258, 0.8379029035568237, 0.9657700061798096, 0.754294216632843, 0.6866182684898376, 0.8664124608039856, 0.693102240562439, 0.9743152856826782, 0.6712689995765686, 0.7789199948310852, 0.8890852928161621, 0.9369409084320068, 0.8858430981636047, 0.7988870739936829, 0.6080878376960754, 0.6991734504699707, 0.7880584597587585, 0.5911555886268616, 0.851848840713501, 0.9951673746109009, 0.9631690382957458, 0.9750829339027405, 0.9125193357467651, 0.695021390914917, 0.928798496723175, 0.9835065603256226, 0.8825098872184753, 0.7888975739479065, 0.9963014125823975, 0.8845154047012329, 0.9885099530220032, 0.9862020611763, 0.9903268218040466, 0.9780688285827637, 0.9920300245285034, 0.9735813736915588, 0.6243914365768433, 0.9319445490837097, 0.7111958861351013, 0.9994058609008789, 0.8876572847366333, 0.8782827854156494, 0.9996989965438843, 0.9997581839561462, 0.7481189966201782, 0.9834923148155212, 0.9458083510398865, 0.624383807182312, 0.7717400789260864, 0.9241034388542175, 0.8419432640075684, 0.9918555021286011, 0.5004332065582275, 0.7935670018196106, 0.6979838609695435, 0.9386588931083679, 0.991916835308075, 0.9998875856399536, 0.9983417987823486, 0.9916911125183105, 0.7702593207359314, 0.9991264939308167, 0.999614953994751, 0.9992228746414185, 0.7785725593566895, 0.9666252732276917, 0.6642624735832214, 0.746168315410614, 0.73471599817276, 0.9685705900192261, 0.9700347185134888, 0.9036412239074707, 0.9402570724487305, 0.8990866541862488, 0.9955865144729614, 0.5901801586151123, 0.9009078741073608, 0.7289243936538696, 0.6253096461296082, 0.8623011708259583, 0.9418995976448059, 0.8574830889701843, 0.8982706069946289, 0.8977878093719482, 0.51619952917099, 0.860558032989502, 0.9954053163528442, 0.9983599781990051, 0.8388285040855408, 0.999870777130127, 0.974723756313324, 0.9481103420257568, 0.5365957021713257, 0.9912113547325134, 0.9855000376701355, 0.7730004787445068, 0.5467172861099243, 0.9974502921104431, 0.9888235926628113, 0.5207819938659668, 0.9903427362442017, 0.998223602771759, 0.9884665012359619, 0.999890923500061, 0.9983194470405579, 0.9925099611282349, 0.8717370629310608, 0.999767005443573, 0.9998010993003845, 0.9665325880050659, 0.7765709757804871, 0.7055303454399109, 0.5158900618553162, 0.8855839371681213, 0.9767953157424927, 0.6577697992324829, 0.9814218282699585, 0.9996125102043152, 0.9994725584983826, 0.8909081816673279, 0.840813159942627, 0.998461127281189, 0.9997566342353821, 0.9344270825386047, 0.8804336190223694, 0.9987472295761108, 0.9716008305549622, 0.6405903100967407, 0.7447956204414368, 0.9896843433380127, 0.9661155343055725, 0.7371419668197632, 0.6237565875053406, 0.988381564617157, 0.8028759956359863, 0.9687591195106506, 0.7742469310760498, 0.9979762434959412, 0.9998986721038818, 0.9993225336074829, 0.9975852966308594, 0.7804101705551147, 0.9998350143432617, 0.9998998641967773, 0.9993454813957214, 0.812967836856842, 0.9977980852127075, 0.9628046751022339, 0.7391895055770874, 0.9877861738204956, 0.9931118488311768, 0.8911281228065491, 0.9985692501068115, 0.9921128749847412, 0.9542840123176575, 0.5523362755775452, 0.9966431856155396, 0.999365508556366, 0.5262916088104248, 0.9954924583435059, 0.8418667912483215, 0.6554486155509949, 0.9825876355171204, 0.9962137341499329, 0.9316653609275818, 0.8053295612335205, 0.5100713968276978, 0.9061132669448853, 0.8723589181900024, 0.793528139591217, 0.9088585376739502, 0.9495294094085693, 0.503814160823822, 0.8241364359855652, 0.6557261943817139, 0.9335377812385559, 0.876638650894165, 0.6980575323104858, 0.8310930728912354, 0.5614501237869263, 0.8710799813270569, 0.8700860142707825, 0.8490377068519592, 0.9659489393234253, 0.9689207673072815, 0.8986533284187317, 0.9909570217132568, 0.7153432369232178, 0.982667863368988, 0.742937445640564, 0.9763918519020081, 0.5594164133071899, 0.8848439455032349, 0.5206530690193176, 0.9874882698059082, 0.9504418969154358, 0.9992892742156982, 0.9281564354896545, 0.9984492063522339, 0.9995657801628113, 0.9985458850860596, 0.5402787923812866, 0.9276804327964783, 0.9923778772354126, 0.9995285272598267, 0.9770166277885437, 0.9801053404808044, 0.895605742931366, 0.6789816617965698, 0.9851908087730408, 0.9904080033302307, 0.9951254725456238, 0.8936274647712708, 0.9944002032279968, 0.6570606231689453, 0.9457513093948364, 0.5823823809623718, 0.6234400868415833, 0.6013652682304382, 0.9404417872428894, 0.998178243637085, 0.9851812124252319, 0.7758035659790039, 0.8235276937484741, 0.9935751557350159, 0.9215834140777588, 0.9908953905105591, 0.9970875382423401, 0.9951936602592468, 0.696875274181366, 0.897377073764801, 0.973796010017395, 0.8567137718200684, 0.9993723034858704, 0.9332582950592041, 0.9956491589546204, 0.9693034291267395, 0.960494339466095, 0.9952465891838074, 0.9156220555305481, 0.9810632467269897, 0.9534942507743835, 0.9311485290527344, 0.5746095180511475, 0.9700464010238647, 0.9500105381011963, 0.9772102236747742, 0.8616951107978821, 0.9966049194335938, 0.5079574584960938, 0.7948594689369202, 0.5347832441329956, 0.8032505512237549, 0.6658416390419006, 0.69426029920578, 0.9947474598884583, 0.5578545928001404, 0.6232097744941711, 0.9359424710273743, 0.8476088047027588, 0.9534134268760681, 0.8482224345207214, 0.8985608220100403, 0.7626602649688721, 0.5565330386161804, 0.6326014995574951, 0.9533356428146362, 0.8040610551834106, 0.948324978351593, 0.9195935726165771, 0.8949671983718872, 0.9816856384277344, 0.766151487827301, 0.9793865084648132, 0.9739157557487488, 0.5495549440383911, 0.9727109670639038, 0.9987303614616394, 0.9981929659843445, 0.9998272061347961, 0.9987035989761353, 0.9999067783355713, 0.6222532391548157, 0.9996103644371033, 0.9967922568321228, 0.9197982549667358, 0.9746251106262207, 0.6351742744445801, 0.9886876344680786, 0.991028904914856, 0.9757733345031738, 0.5771504640579224, 0.9452175498008728, 0.9981016516685486, 0.954683780670166, 0.73548424243927, 0.863294780254364, 0.9857097864151001, 0.7801579833030701, 0.8803081512451172, 0.853023111820221, 0.7384923100471497, 0.7802848219871521, 0.5849115252494812, 0.6001124978065491, 0.7914324402809143, 0.7580440640449524, 0.8650261759757996, 0.6766967177391052, 0.9361518025398254, 0.9373096227645874, 0.995151162147522, 0.5590773820877075, 0.9858596920967102, 0.8905072808265686, 0.5129830241203308, 0.9611871242523193, 0.9680202603340149, 0.9984707236289978, 0.6270588636398315, 0.9957059025764465, 0.9555122256278992, 0.7848057150840759, 0.979709267616272, 0.9922656416893005, 0.7246840596199036, 0.9059780240058899, 0.897473156452179, 0.9139569997787476, 0.886786162853241, 0.9865975975990295, 0.9997195601463318, 0.5599532127380371, 0.791368305683136, 0.8453676700592041, 0.9985083937644958, 0.9995416402816772, 0.641030490398407, 0.6632381677627563, 0.6969139575958252, 0.5100709199905396, 0.9006417393684387, 0.9773855805397034, 0.9786108136177063, 0.9495803713798523, 0.9750615954399109, 0.8471992015838623, 0.9887703657150269, 0.9754135012626648, 0.9860848188400269, 0.5461417436599731, 0.9915279150009155, 0.766664981842041, 0.9746500253677368, 0.9322100877761841, 0.986561119556427, 0.8997118473052979, 0.8459295630455017, 0.6556875109672546, 0.508489191532135, 0.7010151743888855, 0.9701395034790039, 0.5528410077095032, 0.9567444324493408, 0.9995811581611633, 0.9069718718528748, 0.9524005651473999, 0.5407493710517883, 0.7724599242210388, 0.7671058773994446, 0.9675073623657227, 0.997998058795929, 0.6705945730209351, 0.9622411131858826, 0.8287826180458069, 0.8947443962097168, 0.6361219882965088, 0.9761378765106201, 0.5998650193214417, 0.7860394716262817, 0.6593064665794373, 0.8157131671905518, 0.7163266539573669, 0.9651641249656677, 0.5008803606033325, 0.9308476448059082, 0.8021438717842102, 0.8879616260528564, 0.9107206463813782, 0.593009889125824, 0.6604068279266357, 0.8787384629249573, 0.6527355909347534, 0.7158024311065674, 0.8199711441993713, 0.773607611656189, 0.974573016166687, 0.9682714343070984, 0.8499376773834229, 0.9615024328231812, 0.8856843709945679, 0.8632076382637024, 0.7812354564666748, 0.9563650488853455, 0.8708251118659973, 0.5230898857116699, 0.7574166655540466, 0.5084824562072754, 0.5467393398284912, 0.5425012707710266, 0.666501522064209, 0.8981903791427612, 0.905089259147644, 0.9833864569664001, 0.9177756309509277, 0.7433021664619446, 0.6853777170181274, 0.9983096122741699, 0.9966850876808167, 0.8935539722442627, 0.8813040256500244, 0.8093907237052917, 0.9820330739021301, 0.987817108631134, 0.9993360638618469, 0.8855364322662354, 0.998542308807373, 0.6392824649810791, 0.8880757093429565, 0.9923940896987915, 0.6492452621459961, 0.5573474764823914, 0.999578058719635, 0.9999176263809204, 0.6614766716957092, 0.9954711198806763, 0.9993137121200562, 0.8109826445579529, 0.9907711744308472, 0.9968318343162537, 0.5007655024528503, 0.9998587369918823, 0.6662638187408447, 0.9687925577163696, 0.5644203424453735, 0.7855073809623718, 0.9892432689666748, 0.6185843348503113, 0.6392330527305603, 0.9243594408035278, 0.7337533831596375, 0.9865760803222656, 0.9222408533096313, 0.9802061319351196, 0.9152312874794006, 0.7765624523162842, 0.9261052012443542, 0.9608550667762756, 0.862302303314209, 0.5562450289726257, 0.9998619556427002, 0.9875946044921875, 0.9857914447784424, 0.8601497411727905, 0.922835111618042, 0.8452290296554565, 0.977462649345398, 0.8094043731689453, 0.5095643997192383, 0.6319068074226379, 0.8176044225692749, 0.9931898713111877, 0.8431902527809143, 0.8938944935798645, 0.9734402894973755, 0.9994189739227295, 0.9976463913917542, 0.9993342757225037, 0.9991859793663025, 0.5553136467933655, 0.9998993873596191, 0.9649506211280823, 0.9669688940048218, 0.5130845904350281, 0.8745407462120056, 0.9972513318061829, 0.8885335326194763, 0.826688826084137, 0.6804516315460205, 0.9425883889198303, 0.9930574893951416, 0.9976444840431213, 0.9952874183654785, 0.9998761415481567, 0.6517474055290222, 0.9919513463973999, 0.9997504353523254, 0.6359965801239014, 0.9998107552528381, 0.6263201832771301, 0.9261848330497742, 0.7562310695648193, 0.875959038734436, 0.8457778096199036, 0.992012083530426, 0.8051427602767944, 0.5676217079162598, 0.5630945563316345, 0.9411581158638, 0.9998807907104492, 0.7892405390739441, 0.9962978959083557, 0.5236209034919739, 0.9998892545700073, 0.9939914345741272, 0.9994518160820007, 0.6397597789764404, 0.8440051674842834, 0.573750913143158, 0.9998680353164673, 0.9985411167144775, 0.9888581037521362, 0.7840375900268555, 0.9991838335990906, 0.9996652603149414, 0.9640515446662903, 0.9906361699104309, 0.9674360752105713, 0.999596893787384, 0.9484257698059082, 0.5503396987915039, 0.7178077697753906, 0.9199788570404053, 0.978400707244873, 0.5741868019104004, 0.7822283506393433, 0.9931743741035461, 0.7202755212783813, 0.9932706952095032, 0.985358715057373, 0.9965376853942871, 0.997885525226593, 0.9953976273536682, 0.9944023489952087, 0.8790982961654663, 0.9911240339279175, 0.5501335263252258, 0.6734522581100464, 0.8810625672340393, 0.9419997930526733, 0.9979146122932434, 0.699580729007721, 0.9987892508506775, 0.9291504621505737, 0.997641921043396, 0.9387353658676147, 0.6863906383514404, 0.6809191703796387, 0.9990359544754028, 0.805984377861023, 0.9981075525283813, 0.9994170665740967, 0.9999029636383057, 0.9188472032546997, 0.8013538122177124, 0.9968230724334717, 0.9977669715881348, 0.9985458850860596, 0.9988202452659607, 0.9908189177513123, 0.9943793416023254, 0.9964959025382996, 0.8560618162155151, 0.8740831017494202, 0.999778687953949, 0.9999234676361084, 0.999950647354126, 0.9551039338111877, 0.9924923777580261, 0.9908375144004822, 0.9993950128555298, 0.8113405108451843, 0.9997050166130066, 0.9987682700157166, 0.9763134121894836, 0.9996500015258789, 0.9990361928939819, 0.9918599724769592, 0.9932100176811218, 0.7725992798805237, 0.618394672870636, 0.6720781326293945, 0.7238768935203552, 0.7792648077011108, 0.9977462887763977, 0.9553809762001038, 0.81764155626297, 0.9992026686668396, 0.9844340682029724, 0.9879465699195862, 0.8285771608352661, 0.817877471446991, 0.9731148481369019, 0.9650780558586121, 0.9983407258987427, 0.7325698733329773, 0.8796200156211853, 0.9913002848625183, 0.752964437007904, 0.984373927116394, 0.9152965545654297, 0.9397249817848206, 0.9781785607337952, 0.9998809099197388, 0.9231520891189575, 0.9982497096061707, 0.999896764755249, 0.9999345541000366, 0.7921846508979797, 0.9992222785949707, 0.9997512698173523, 0.90237957239151, 0.9997839331626892, 0.7968484163284302, 0.9932733774185181, 0.9723301529884338, 0.6569542288780212, 0.9998444318771362, 0.8821902871131897, 0.9973812699317932, 0.9781437516212463, 0.9968854784965515, 0.8053106069564819, 0.9977359771728516, 0.9912554025650024, 0.9981896281242371, 0.9850260615348816, 0.9684374332427979, 0.9967557787895203, 0.9972922205924988, 0.5196328163146973, 0.9951015114784241, 0.8288975954055786, 0.999688982963562, 0.982344925403595, 0.9824751019477844, 0.9877249598503113, 0.9979111552238464, 0.9809880256652832, 0.9582700729370117, 0.8160303831100464, 0.9234904050827026, 0.5246935486793518, 0.8358222246170044, 0.9974395036697388, 0.9794344305992126, 0.9646259546279907, 0.6676050424575806, 0.8915724158287048, 0.5167009830474854, 0.8630067110061646, 0.9999005794525146, 0.8980427980422974, 0.9998911619186401, 0.6910011172294617, 0.8805628418922424, 0.9347666501998901, 0.9998832941055298, 0.9744291305541992, 0.9725010991096497, 0.7345792055130005, 0.8813154101371765, 0.9799841046333313, 0.9068202972412109, 0.8759030699729919, 0.8372933864593506, 0.7768691182136536, 0.9906401634216309, 0.5575442314147949, 0.9873303174972534, 0.9976609945297241, 0.7797494530677795, 0.9840676784515381, 0.6884137392044067, 0.5022852420806885, 0.9661258459091187, 0.9859206080436707, 0.9819719195365906, 0.989605188369751, 0.9983668923377991, 0.9976243376731873, 0.5524585247039795, 0.9834674000740051, 0.9971354007720947, 0.8803715705871582, 0.5106993913650513, 0.6188400983810425, 0.5460198521614075, 0.7091304659843445, 0.9931830763816833, 0.6767556071281433, 0.7629501819610596, 0.9747947454452515, 0.9988147020339966, 0.9933068156242371, 0.9909200668334961, 0.8909167051315308, 0.746471643447876, 0.7689980268478394, 0.9128515124320984, 0.8068143129348755, 0.5066618323326111, 0.804962694644928, 0.8878561854362488, 0.5513938069343567, 0.8229150772094727, 0.9727950096130371, 0.9090754389762878, 0.840031623840332, 0.9713312387466431, 0.5974531769752502, 0.8135276436805725, 0.6358759999275208, 0.8246472477912903, 0.9358248114585876, 0.72159743309021, 0.9933428764343262, 0.9854264259338379, 0.9997627139091492, 0.9975662231445312, 0.7578428983688354, 0.8242881298065186, 0.9637628197669983, 0.7804920077323914, 0.9693922996520996, 0.7333295941352844, 0.9060125350952148, 0.9862625598907471, 0.9979543685913086, 0.8686321377754211, 0.754423201084137, 0.9633446931838989, 0.6462319493293762, 0.8455633521080017, 0.9808488488197327, 0.9512471556663513, 0.9676037430763245, 0.938776969909668, 0.8884263038635254, 0.9098621606826782, 0.9903019070625305, 0.9680057168006897, 0.7567331790924072, 0.9993983507156372, 0.9759886860847473, 0.5811554193496704, 0.9987548589706421, 0.8010409474372864, 0.9957982897758484, 0.6542482972145081, 0.9951812624931335, 0.9800167083740234, 0.9860289692878723, 0.9672176241874695, 0.9591779708862305, 0.9717655777931213, 0.5707484483718872, 0.8288599252700806, 0.9998767375946045, 0.7573030591011047, 0.706154465675354, 0.9859733581542969, 0.7689573764801025, 0.7105529308319092, 0.9437281489372253, 0.9853327870368958, 0.9929611086845398, 0.565226137638092, 0.9986668825149536, 0.98275226354599, 0.5068157315254211, 0.999113142490387, 0.9482850432395935, 0.9810092449188232, 0.9962881803512573, 0.7550978064537048, 0.9970368146896362, 0.9983029365539551, 0.6342161297798157, 0.9966513514518738, 0.6768370866775513, 0.9717373251914978, 0.5576475858688354, 0.9981892704963684, 0.9961652755737305, 0.9782912731170654, 0.9994428753852844, 0.9997597336769104, 0.6964094638824463, 0.9623866081237793, 0.7686386108398438, 0.8366380929946899, 0.9943767786026001, 0.7801775336265564, 0.8663007020950317, 0.9976006150245667, 0.8947640657424927, 0.9943408966064453, 0.6095492243766785, 0.9998900890350342, 0.8278610706329346, 0.9647345542907715, 0.8726445436477661, 0.7738391160964966, 0.9985496401786804, 0.6926916241645813, 0.6105678081512451, 0.9824981093406677, 0.7603467106819153, 0.9997991919517517, 0.8543977737426758, 0.9966200590133667, 0.9375134706497192, 0.9997764229774475, 0.9838053584098816, 0.9998078942298889, 0.8641102910041809, 0.7368494272232056, 0.9999059438705444, 0.6855819225311279, 0.9999005794525146, 0.9977189898490906, 0.8830077648162842, 0.7714399695396423, 0.6978949308395386, 0.643298864364624, 0.9998286962509155, 0.994917631149292, 0.9996976852416992, 0.972183883190155, 0.9995278120040894, 0.994509756565094, 0.9996935129165649, 0.758062481880188, 0.8224976062774658, 0.9241549372673035, 0.5241776704788208, 0.9998314380645752, 0.7019620537757874, 0.9881187081336975, 0.9534330368041992, 0.9293385148048401, 0.9985266923904419, 0.9996323585510254, 0.9998145699501038, 0.9055954217910767, 0.9994576573371887, 0.9996986389160156, 0.9999034404754639, 0.7843478322029114, 0.8210792541503906, 0.5766612887382507, 0.9998268485069275, 0.9998668432235718, 0.9970499277114868, 0.9998434782028198, 0.9989708662033081, 0.857453465461731, 0.999796450138092, 0.956668496131897, 0.5451043844223022, 0.9998637437820435, 0.9815095663070679, 0.5318458676338196, 0.999739944934845, 0.9806828498840332, 0.9992846846580505, 0.7044103145599365, 0.9989840388298035, 0.9989559650421143, 0.868331789970398, 0.9501141309738159, 0.8804609775543213, 0.9982450008392334, 0.9961789846420288, 0.9966566562652588, 0.9739868640899658, 0.9962499737739563, 0.9959431290626526, 0.9777570366859436, 0.9998008608818054, 0.9988870024681091, 0.6295986175537109, 0.9639971852302551, 0.829470694065094, 0.9745041728019714, 0.8598629236221313, 0.988585889339447, 0.9946993589401245, 0.995121419429779, 0.8357957601547241, 0.5411761999130249, 0.9404531717300415, 0.6352095603942871, 0.5247385501861572, 0.8677866458892822, 0.6810856461524963, 0.8205081820487976, 0.9988611936569214, 0.8557290434837341, 0.9919551014900208, 0.7929264307022095, 0.5495887994766235, 0.9551330804824829, 0.9961226582527161, 0.9257206320762634, 0.7576310634613037, 0.9980142116546631, 0.9818567633628845, 0.9391310811042786, 0.9974835515022278, 0.9523497223854065, 0.8436901569366455, 0.9964820146560669, 0.8259318470954895, 0.5554177165031433, 0.5959962010383606, 0.961702287197113, 0.729839026927948, 0.9657889604568481, 0.9933510422706604, 0.9797779321670532, 0.9627835750579834, 0.8999078273773193, 0.9669678807258606, 0.542830765247345, 0.9996579885482788, 0.5617245435714722, 0.5565004348754883, 0.9866179823875427, 0.9798852205276489, 0.9889953136444092, 0.9119338989257812, 0.9536296725273132, 0.8826485276222229, 0.6710682511329651, 0.7764765024185181, 0.9982409477233887, 0.9735795855522156, 0.999870777130127, 0.8478613495826721, 0.9992231130599976, 0.9465153813362122, 0.9322822690010071, 0.802732527256012, 0.9993884563446045, 0.7368977069854736, 0.8074550628662109, 0.5507813692092896, 0.9226927757263184, 0.8310455083847046, 0.7047846913337708, 0.8952895402908325, 0.993911623954773, 0.999369204044342, 0.9958071708679199, 0.945921003818512, 0.9974019527435303, 0.9995158910751343, 0.9701613783836365, 0.8915868401527405, 0.8859568238258362, 0.8760800361633301, 0.9905843734741211, 0.6579549312591553, 0.8899171948432922, 0.9922564029693604, 0.8003389835357666, 0.5281848311424255, 0.9629517793655396, 0.9906266927719116, 0.9284899830818176, 0.7431108355522156, 0.7818514704704285, 0.8215489387512207, 0.9455907344818115, 0.5417675375938416, 0.7065839767456055, 0.9576936364173889, 0.6607767343521118, 0.9341551065444946, 0.9998828172683716, 0.9983034133911133, 0.9997649788856506, 0.9291467070579529, 0.6464711427688599, 0.8885964155197144, 0.9732058048248291, 0.8744714856147766, 0.9260024428367615, 0.8333567976951599, 0.9932578802108765, 0.7956667542457581, 0.9954256415367126, 0.9230482578277588, 0.7517678141593933, 0.999147891998291, 0.994962215423584, 0.9984607696533203, 0.6607694029808044, 0.6716146469116211, 0.9999086856842041, 0.9962652325630188, 0.9992733597755432, 0.9994367957115173, 0.9983395338058472, 0.9858945608139038, 0.9974278807640076, 0.8798320889472961, 0.990591824054718, 0.8935194611549377, 0.8941823244094849, 0.9943642616271973, 0.7085422277450562, 0.9998500347137451, 0.999947190284729, 0.5920189619064331, 0.9988325238227844, 0.9994688630104065, 0.9999574422836304, 0.9997219443321228, 0.9868196845054626, 0.998904824256897, 0.9919161200523376, 0.9984814524650574, 0.9277775883674622, 0.9949660897254944, 0.9993219375610352, 0.9943209886550903, 0.5074537396430969, 0.9941157102584839, 0.908564031124115, 0.9501237273216248, 0.9791883826255798, 0.999886155128479, 0.9998981952667236, 0.9485286474227905, 0.7580791115760803, 0.9995439648628235, 0.9987568855285645, 0.9971283078193665, 0.9905940294265747, 0.9987484216690063, 0.9025346040725708, 0.9987014532089233, 0.9977160692214966, 0.9997532963752747, 0.9915167093276978, 0.9993112087249756, 0.9917687177658081, 0.9994897842407227, 0.5690796375274658, 0.999893069267273, 0.9995996356010437, 0.999916672706604, 0.9997773766517639, 0.9997057318687439, 0.9118816256523132, 0.9959378242492676, 0.9997100234031677, 0.9770784974098206, 0.9986070990562439, 0.9843728542327881, 0.9765353798866272, 0.9958193302154541, 0.8079516887664795, 0.9995881915092468, 0.9982580542564392, 0.9995649456977844, 0.9220137000083923, 0.9861432909965515, 0.9923520684242249, 0.9955586194992065, 0.6433799862861633, 0.9537043571472168, 0.9772820472717285, 0.9975875616073608, 0.8694485425949097, 0.9869136214256287, 0.9997343420982361, 0.9998677968978882, 0.9992163181304932, 0.9995330572128296, 0.9957299828529358, 0.5295180082321167, 0.9459494948387146, 0.6014927625656128, 0.9992916584014893, 0.5826228857040405, 0.9998832941055298, 0.9997628331184387, 0.9998171925544739, 0.801631510257721, 0.9941717982292175, 0.9998573064804077, 0.9999281167984009, 0.9997124075889587, 0.8147493600845337, 0.9551986455917358, 0.9876505732536316, 0.966809093952179, 0.9998173117637634, 0.9998973608016968, 0.9695629477500916, 0.5249112248420715, 0.9022982120513916, 0.9991925358772278, 0.9989295601844788, 0.9981710910797119, 0.7583860754966736, 0.9821872711181641, 0.9999321699142456, 0.9999548196792603, 0.7477502226829529, 0.8563602566719055, 0.9980954527854919, 0.9892370104789734, 0.9984955787658691, 0.751099705696106, 0.7687034010887146, 0.7593780755996704, 0.9609211087226868, 0.8453533053398132, 0.7689890265464783, 0.9156557321548462, 0.8615603446960449, 0.9292255640029907, 0.7451696991920471, 0.94113689661026, 0.8002831339836121, 0.9869945645332336, 0.5002670884132385, 0.9933660626411438, 0.9757401943206787, 0.9993029832839966, 0.7367669939994812, 0.8906646370887756, 0.9528577327728271, 0.9836739301681519, 0.9626765847206116, 0.5382588505744934, 0.8582822680473328, 0.9604839086532593, 0.917046844959259, 0.9648805856704712, 0.9001016616821289, 0.619510293006897, 0.9931026697158813, 0.9921097159385681, 0.9622021317481995, 0.8659126162528992, 0.997631311416626, 0.9989824891090393, 0.6712112426757812, 0.886242151260376, 0.6117100119590759, 0.8835392594337463, 0.7159751057624817, 0.847092866897583, 0.7698082327842712, 0.6333824992179871, 0.6639458537101746, 0.5545608997344971, 0.8422554135322571, 0.9799200892448425, 0.9483062624931335, 0.9913806319236755, 0.9909624457359314, 0.8283334970474243, 0.7658750414848328, 0.9515115022659302, 0.9747356176376343, 0.548173189163208, 0.9987672567367554, 0.7117288708686829, 0.9153791666030884, 0.9944462776184082, 0.5782509446144104, 0.976538896560669, 0.9940703511238098, 0.6376480460166931, 0.8656554222106934, 0.921617865562439, 0.6986743211746216, 0.8373168110847473, 0.9470295906066895, 0.7133336663246155, 0.8877441883087158, 0.9856747984886169, 0.9392387270927429, 0.861275315284729, 0.6044828295707703, 0.8567384481430054, 0.9722135066986084, 0.9026533961296082, 0.8009243011474609, 0.7978966236114502, 0.8064813017845154, 0.991193950176239, 0.980902910232544, 0.6812881827354431, 0.5874657034873962, 0.9099481105804443, 0.974322497844696, 0.7439308762550354, 0.7690297961235046, 0.9944975972175598, 0.79330974817276, 0.6973912715911865, 0.9250933527946472, 0.9887043833732605, 0.9794647097587585, 0.8644969463348389, 0.9984093308448792, 0.5860278606414795, 0.9935526847839355, 0.9664266109466553, 0.989551842212677, 0.6831955909729004, 0.6218263506889343, 0.9420770406723022, 0.9433012008666992, 0.7819425463676453, 0.9971242547035217, 0.7480244040489197, 0.9980223178863525, 0.9835652709007263, 0.9989045858383179, 0.987155556678772, 0.9966866374015808, 0.9758250713348389, 0.968316912651062, 0.9906485676765442, 0.9029405117034912, 0.9581232070922852, 0.724788248538971, 0.9218336939811707, 0.5499711036682129, 0.6707175374031067, 0.9833901524543762, 0.9203254580497742, 0.9992031455039978, 0.9997133612632751, 0.8014837503433228, 0.6559129953384399, 0.9701846837997437, 0.7323517799377441, 0.9887750148773193, 0.8260523080825806, 0.6833564639091492, 0.7445020079612732, 0.521958589553833, 0.855956494808197, 0.6076610088348389, 0.9992721676826477, 0.9997655749320984, 0.9996658563613892, 0.7234187126159668, 0.8642098903656006, 0.949738621711731, 0.8590351343154907, 0.9193229079246521, 0.954975426197052, 0.6894897222518921, 0.9782702922821045, 0.9560199975967407, 0.9900904893875122, 0.9922713041305542, 0.5136749148368835, 0.9944742321968079, 0.987212598323822, 0.9971176385879517, 0.997983455657959, 0.7144090533256531, 0.997885525226593, 0.8624492883682251, 0.993961751461029, 0.8899701833724976, 0.9963009357452393, 0.9697508811950684, 0.5701510906219482, 0.7963922023773193, 0.9673179388046265, 0.9602165222167969, 0.9913007616996765, 0.9528919458389282, 0.5548239946365356, 0.8269597887992859, 0.9550681710243225, 0.9843952655792236, 0.9014365673065186, 0.6565468311309814, 0.9631900191307068, 0.9313005805015564, 0.7626492381095886, 0.9860160946846008, 0.5573809146881104, 0.9983857870101929, 0.9913471341133118, 0.9865575432777405, 0.9968205690383911, 0.9997604489326477, 0.998525083065033, 0.9949513673782349, 0.8715709447860718, 0.9995357990264893, 0.9998836517333984, 0.8653422594070435, 0.6390230059623718, 0.9159559011459351, 0.532997727394104, 0.9961773157119751, 0.9985068440437317, 0.6029171347618103, 0.9987413287162781, 0.9893933534622192, 0.9903222918510437, 0.9949402809143066, 0.9657325744628906, 0.987209677696228, 0.9407175779342651, 0.5217543840408325, 0.9596010446548462, 0.9998916387557983, 0.539064347743988, 0.9842722415924072, 0.9877947568893433, 0.9995324611663818, 0.9993026256561279, 0.9987637996673584, 0.9468966126441956, 0.8235489726066589, 0.9988993406295776, 0.6525301933288574, 0.7100337147712708, 0.8266675472259521, 0.9980595707893372, 0.9943073391914368, 0.9996410608291626, 0.9997995495796204, 0.819953441619873, 0.999904990196228, 0.907573938369751, 0.7685924172401428, 0.5739046931266785, 0.8893440365791321, 0.998976469039917, 0.9998231530189514, 0.9825785160064697, 0.9940314888954163, 0.9950474500656128, 0.6634216904640198, 0.9056636095046997, 0.9471344947814941, 0.8123334050178528, 0.960513710975647, 0.6369229555130005, 0.9999014139175415, 0.9996713399887085, 0.9998835325241089, 0.9699945449829102, 0.9925523996353149, 0.7484001517295837, 0.992679238319397, 0.9955025315284729, 0.9777352809906006, 0.7517272233963013, 0.999779999256134, 0.9616449475288391, 0.9933239817619324, 0.9929261207580566, 0.8749906420707703, 0.7473127245903015, 0.7183372378349304, 0.5664641857147217, 0.8987793922424316, 0.9981753826141357, 0.9998787641525269, 0.9997047781944275, 0.9839801788330078, 0.9993435740470886, 0.9963233470916748, 0.949069082736969, 0.5087758898735046, 0.856362521648407, 0.9189013242721558, 0.899446427822113, 0.9394052624702454, 0.9901048541069031, 0.9096693992614746, 0.832302987575531, 0.9989932179450989, 0.9688131213188171, 0.5221270322799683, 0.8218791484832764, 0.9285699129104614, 0.9331752061843872, 0.9993775486946106, 0.9892667531967163, 0.5231723785400391, 0.9951098561286926, 0.9998076558113098, 0.9970302581787109, 0.9996380805969238, 0.9752272367477417, 0.9993886947631836, 0.9968974590301514, 0.978417694568634, 0.9970122575759888, 0.8884305357933044, 0.9956569671630859, 0.9843617677688599, 0.9818837642669678, 0.9951183795928955, 0.8137052059173584, 0.9961251616477966, 0.8344061374664307, 0.9382432699203491, 0.74139404296875, 0.999889612197876, 0.9994961023330688, 0.9998327493667603, 0.6784831881523132, 0.9998980760574341, 0.9996501207351685, 0.9998745918273926, 0.9908660054206848, 0.9883252382278442, 0.9988610744476318, 0.9919084906578064, 0.5286059975624084, 0.7672041058540344, 0.7741132974624634, 0.999384880065918, 0.9763756990432739, 0.9968129992485046, 0.9998977184295654, 0.9971764087677002, 0.9999144077301025, 0.9997373223304749, 0.8926704525947571, 0.9983188509941101, 0.9962047934532166, 0.9999054670333862, 0.9999566078186035, 0.5536857843399048, 0.9960648417472839, 0.9938803911209106, 0.9984344840049744, 0.9914121627807617, 0.608425498008728, 0.979759156703949, 0.9993374943733215, 0.695919394493103, 0.5607567429542542, 0.5198917388916016, 0.9981784820556641, 0.9681863784790039, 0.9992669224739075, 0.9406174421310425, 0.9991274476051331, 0.9998062252998352, 0.9860801100730896, 0.9732558727264404, 0.957789421081543, 0.8649422526359558, 0.9865952730178833, 0.9793494343757629, 0.9634589552879333, 0.8922473788261414, 0.995209276676178, 0.965851902961731, 0.9998706579208374, 0.8368499279022217, 0.9921554923057556, 0.9726971387863159, 0.9981643557548523, 0.9904665350914001, 0.9905989766120911, 0.6437600255012512, 0.9924142956733704, 0.9188574552536011, 0.9981244206428528, 0.9995124340057373, 0.9488781690597534, 0.9116477370262146, 0.8912761211395264, 0.6160256266593933, 0.9967957139015198, 0.5009129643440247, 0.9999046325683594, 0.9994155168533325, 0.9997196793556213, 0.9682687520980835, 0.999808132648468, 0.8659473657608032, 0.7263662815093994, 0.9971349239349365, 0.8291417956352234, 0.7382119297981262, 0.9547058343887329, 0.9967043995857239, 0.5166372060775757, 0.9999009370803833, 0.999852180480957, 0.9999293088912964, 0.9842549562454224, 0.9981300234794617, 0.9717369675636292, 0.9998778104782104, 0.9127440452575684, 0.908562958240509, 0.6141788363456726, 0.9738198518753052, 0.8041673302650452, 0.9607641100883484, 0.6272866129875183, 0.5618641376495361, 0.8626813292503357, 0.9539961218833923, 0.9759699106216431, 0.9856644868850708, 0.9998892545700073, 0.9992570281028748, 0.9394549131393433, 0.9980733394622803, 0.9988319277763367, 0.9109860062599182, 0.9997298121452332, 0.968264639377594, 0.9991408586502075, 0.999479353427887, 0.7478703260421753, 0.9998725652694702, 0.9939640164375305, 0.9749717116355896, 0.8266273736953735, 0.9961556792259216, 0.6682705879211426, 0.9853944778442383, 0.793790876865387, 0.9617797136306763, 0.7963033318519592, 0.9924001693725586, 0.9667105078697205, 0.993242084980011, 0.7444083094596863, 0.9261946678161621, 0.9932768940925598, 0.9993308782577515, 0.6931530237197876, 0.999872088432312, 0.6328451633453369, 0.9733359217643738, 0.6715654134750366, 0.830562174320221, 0.9925709366798401, 0.9804398417472839, 0.7656809687614441, 0.5773317813873291, 0.898222029209137, 0.9575486779212952, 0.6241205334663391, 0.535048246383667, 0.893701434135437, 0.6339524388313293, 0.8016395568847656, 0.5512655377388, 0.8944655060768127, 0.5891978740692139, 0.5142440795898438, 0.9875984787940979, 0.9574006795883179, 0.7999292016029358, 0.9926674962043762, 0.9221495389938354, 0.8473278880119324, 0.9726167917251587, 0.8784394264221191, 0.9590616226196289, 0.9994792342185974, 0.7073197960853577, 0.8978811502456665, 0.8894492983818054, 0.849547266960144, 0.9738833904266357, 0.8733772039413452, 0.9934011101722717, 0.8849231004714966, 0.9638441205024719, 0.5585834980010986, 0.9999077320098877, 0.9992289543151855, 0.9997114539146423, 0.9981662631034851, 0.9889673590660095, 0.9917600750923157, 0.9861888289451599, 0.9992223978042603, 0.9980906844139099, 0.8795574903488159, 0.8940060138702393, 0.9633588194847107, 0.7030549049377441, 0.9998385906219482, 0.5243823528289795, 0.8935234546661377, 0.6642054319381714, 0.9429810047149658, 0.6336451768875122, 0.9777723550796509, 0.8168153762817383, 0.7343173623085022, 0.7245554327964783, 0.9982441663742065, 0.9324457049369812, 0.8962109684944153, 0.9863771796226501, 0.7992216348648071, 0.6484541893005371, 0.5116047263145447, 0.6588598489761353, 0.7884582281112671, 0.7478253245353699, 0.996260404586792, 0.9603080749511719, 0.9838309288024902, 0.9964193105697632, 0.9982960820198059, 0.9996558427810669, 0.5035169720649719, 0.999886155128479, 0.9874237179756165, 0.9910489320755005, 0.9785192608833313, 0.9533601403236389, 0.9882241487503052, 0.85298752784729, 0.9913289546966553, 0.9014977812767029, 0.5925300717353821, 0.5078635811805725, 0.5308666229248047, 0.8574892282485962, 0.9996823072433472, 0.7022106647491455, 0.7617210149765015, 0.9509310722351074, 0.723110556602478, 0.9972639083862305, 0.9819216728210449, 0.9639270305633545, 0.7880048751831055, 0.999442994594574, 0.7359666228294373, 0.9630385637283325, 0.9985484480857849, 0.9305621981620789, 0.9999170303344727, 0.9999575614929199, 0.9937676191329956, 0.9996193647384644, 0.9998168349266052, 0.9991341233253479, 0.9988409876823425, 0.999521017074585, 0.9958090782165527, 0.987276017665863, 0.9899744391441345, 0.9978821873664856, 0.9974446296691895, 0.9506310820579529, 0.9643092155456543, 0.9772014617919922, 0.9752559065818787, 0.616237223148346, 0.7947719097137451, 0.9228629469871521, 0.6340436339378357, 0.9805731177330017, 0.9584046006202698, 0.9461511373519897, 0.821999192237854, 0.9874054789543152, 0.9995933175086975, 0.997289776802063, 0.9911952018737793, 0.8112823963165283, 0.9944685697555542, 0.9446141123771667, 0.916924774646759, 0.997588038444519, 0.9982415437698364, 0.9997661709785461, 0.9992750287055969, 0.9994440674781799, 0.9997242093086243, 0.9993185997009277, 0.7816729545593262, 0.985630214214325, 0.9991010427474976, 0.83842933177948, 0.9751833081245422, 0.9924375414848328, 0.999727189540863, 0.9998487234115601, 0.6491614580154419, 0.9845929741859436, 0.8429136276245117, 0.802108108997345, 0.9632405638694763, 0.9926602840423584, 0.9503848552703857, 0.9938302636146545, 0.7718291282653809, 0.8805217146873474, 0.8134986758232117, 0.7596261501312256, 0.8653915524482727, 0.7722073793411255, 0.999595582485199, 0.9984784722328186, 0.999883770942688, 0.917755663394928, 0.988239049911499, 0.9973188042640686, 0.9310780167579651, 0.886498749256134, 0.7382714152336121, 0.7287623286247253, 0.9256071448326111, 0.9580212235450745, 0.9909145832061768, 0.997399091720581, 0.8994330167770386, 0.9938331842422485, 0.877437949180603, 0.9976444840431213, 0.8664008378982544, 0.9986390471458435, 0.9979667663574219, 0.997654139995575, 0.6736279726028442, 0.6646249890327454, 0.5548497438430786, 0.9952483773231506, 0.9289633631706238, 0.784885823726654, 0.7558856010437012, 0.8393964767456055, 0.9823973178863525, 0.9983536005020142, 0.9998347759246826, 0.9171791672706604, 0.9904459714889526, 0.9952817559242249, 0.9993777275085449, 0.7060123085975647, 0.9998989105224609, 0.8490219712257385, 0.9968222379684448, 0.9664639830589294, 0.8461463451385498, 0.8292624354362488, 0.9994327425956726, 0.6513087153434753, 0.9004893898963928, 0.8121532797813416, 0.7670508623123169, 0.9568259716033936, 0.9970607161521912, 0.9986246824264526, 0.996177077293396, 0.6026178598403931, 0.6621381044387817, 0.9999032020568848, 0.9985895752906799, 0.9998971223831177, 0.6074530482292175, 0.9998958110809326, 0.9946269392967224, 0.999858021736145, 0.9935178756713867, 0.9994373917579651, 0.9924315214157104, 0.9779031872749329, 0.9731122255325317, 0.9989749193191528, 0.9958152174949646, 0.9364322423934937, 0.9260956048965454, 0.9904195666313171, 0.9738107323646545, 0.8898731470108032, 0.9223619699478149, 0.5708760619163513, 0.6868985295295715, 0.9769426584243774, 0.9998694658279419, 0.9977916479110718, 0.8732988238334656, 0.9483386278152466, 0.9840710163116455, 0.9993953704833984, 0.9929254055023193, 0.9965157508850098, 0.652201235294342, 0.9989228844642639, 0.517480194568634, 0.7403043508529663, 0.856720507144928, 0.9984027743339539, 0.9828124642372131, 0.9938217401504517, 0.994355320930481, 0.9886415600776672, 0.9984778761863708, 0.7476674318313599, 0.5116372108459473, 0.999552309513092, 0.9997879862785339, 0.6053184866905212, 0.995219886302948, 0.698826253414154, 0.7679287791252136, 0.9997928738594055, 0.9997255206108093, 0.9999160766601562, 0.7023853659629822, 0.9127607345581055, 0.9458592534065247, 0.9988030195236206, 0.7806030511856079, 0.9998856782913208, 0.9966961145401001, 0.9965235590934753, 0.999713122844696, 0.9978371262550354, 0.9997465014457703, 0.9644854068756104, 0.9994962215423584, 0.5789493918418884, 0.9999080896377563, 0.9616129994392395, 0.9991914629936218, 0.521952211856842, 0.7169426679611206, 0.8697513341903687, 0.7520656585693359, 0.5595268607139587, 0.9623896479606628, 0.9805496335029602, 0.8327509164810181, 0.9998886585235596, 0.9997066855430603, 0.9999120235443115, 0.9677925705909729, 0.974025547504425, 0.854759693145752, 0.9893814325332642, 0.8659206628799438, 0.9352228045463562, 0.5269258618354797, 0.9395712018013, 0.6103761792182922, 0.9999079704284668, 0.999213695526123, 0.9783012866973877, 0.58623868227005, 0.8802114725112915, 0.9961608648300171, 0.8808905482292175, 0.5341804623603821, 0.9910100698471069, 0.9997356534004211, 0.9998039603233337, 0.618792712688446, 0.9977266192436218, 0.9475167393684387, 0.8056365251541138, 0.8922644257545471, 0.9836258292198181, 0.8454374670982361, 0.7703821659088135, 0.991263747215271, 0.8354745507240295, 0.8161205649375916, 0.9838150143623352, 0.9931783676147461, 0.9807511568069458, 0.9993866682052612, 0.9263588190078735, 0.8199688196182251, 0.9487339854240417, 0.8485361337661743, 0.9946781396865845, 0.9567922353744507, 0.6137189865112305, 0.9526618719100952, 0.5747026205062866, 0.8066600561141968, 0.6406376361846924, 0.748496413230896, 0.5568968653678894, 0.982926607131958, 0.9830501675605774, 0.9987194538116455, 0.9998667240142822]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\jhluo\\AppData\\Local\\Temp\\ipykernel_9044\\1938414908.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\jhluo\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_9044\\\\1938414908.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\jhluo\\AppData\\Local\\Temp\\ipykernel_9044\\1938414908.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\jhluo\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_9044\\\\1938414908.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'float'</span> object is not iterable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\jhluo\\AppData\\Local\\Temp\\ipykernel_9044\\1938414908.py\u001B[0m:\u001B[94m2\u001B[0m in \u001B[92m<cell line: 2>\u001B[0m               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\jhluo\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_9044\\\\1938414908.py'\u001B[0m                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\jhluo\\AppData\\Local\\Temp\\ipykernel_9044\\1938414908.py\u001B[0m:\u001B[94m2\u001B[0m in \u001B[92m<listcomp>\u001B[0m                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\jhluo\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_9044\\\\1938414908.py'\u001B[0m                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mTypeError: \u001B[0m\u001B[32m'float'\u001B[0m object is not iterable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(all_probabilities)\n",
    "all_probabilities = [max(sublist) for sublist in all_probabilities]\n",
    "print(all_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extract reslut to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic', 'premise', 'hypothesis', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  topic  \\\n",
      "0        Routine child vaccinations should be mandatory   \n",
      "1        Routine child vaccinations should be mandatory   \n",
      "2        Routine child vaccinations should be mandatory   \n",
      "3        Routine child vaccinations should be mandatory   \n",
      "4        Routine child vaccinations should be mandatory   \n",
      "...                                                 ...   \n",
      "3421  Social media platforms should be regulated by ...   \n",
      "3422     Routine child vaccinations should be mandatory   \n",
      "3423     Routine child vaccinations should be mandatory   \n",
      "3424     Routine child vaccinations should be mandatory   \n",
      "3425     Routine child vaccinations should be mandatory   \n",
      "\n",
      "                                                premise  \\\n",
      "0      Routine childhood vaccinations  should be man...   \n",
      "1      Routine childhood vaccinations  should be man...   \n",
      "2      Routine childhood vaccinations  should be man...   \n",
      "3      Routine childhood vaccinations  should be man...   \n",
      "4     Routine child vaccinations isn't mandatory sin...   \n",
      "...                                                 ...   \n",
      "3421  yes, there is some strong content on social me...   \n",
      "3422  you may create a chemical reaction that affect...   \n",
      "3423  you may create a chemical reaction that affect...   \n",
      "3424  you may create a chemical reaction that affect...   \n",
      "3425  you may create a chemical reaction that affect...   \n",
      "\n",
      "                                             hypothesis  label  prediction  \\\n",
      "0              Routine child vaccinations are effective      0           0   \n",
      "1                         Child vaccination saves lives      0           0   \n",
      "2     Routine child vaccinations are necessary to pr...      0           1   \n",
      "3     Routine child vaccinations should be mandatory...      1           1   \n",
      "4     Routine child vaccinations, or their side effe...      0           1   \n",
      "...                                                 ...    ...         ...   \n",
      "3421  Social media regulation is required to deal wi...      0           0   \n",
      "3422  Routine child vaccinations are not necessary t...      0           0   \n",
      "3423  Routine child vaccinations, or their side effe...      1           1   \n",
      "3424     Mandatory vaccination contradicts basic rights      0           0   \n",
      "3425        The parents and not the state should decide      0           0   \n",
      "\n",
      "      probability  \n",
      "0        0.851383  \n",
      "1        0.953045  \n",
      "2        0.981344  \n",
      "3        0.999903  \n",
      "4        0.950211  \n",
      "...           ...  \n",
      "3421     0.556897  \n",
      "3422     0.982927  \n",
      "3423     0.983050  \n",
      "3424     0.998719  \n",
      "3425     0.999867  \n",
      "\n",
      "[3426 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "add_df = pd.DataFrame({\n",
    "    'prediction': all_predictions,\n",
    "    'probability':all_probabilities\n",
    "})\n",
    "result_df = pd.concat([test_df,add_df],axis=1)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to ./result/KPM_official_test.csv\n"
     ]
    }
   ],
   "source": [
    "result_df.to_csv('./result/KPM_official_test.csv', index=False)\n",
    "print(f\"DataFrame has been saved to {'./result/KPM_official_test.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  topic  \\\n",
      "0        Routine child vaccinations should be mandatory   \n",
      "1        Routine child vaccinations should be mandatory   \n",
      "2        Routine child vaccinations should be mandatory   \n",
      "3        Routine child vaccinations should be mandatory   \n",
      "4        Routine child vaccinations should be mandatory   \n",
      "...                                                 ...   \n",
      "3421  Social media platforms should be regulated by ...   \n",
      "3422     Routine child vaccinations should be mandatory   \n",
      "3423     Routine child vaccinations should be mandatory   \n",
      "3424     Routine child vaccinations should be mandatory   \n",
      "3425     Routine child vaccinations should be mandatory   \n",
      "\n",
      "                                                premise  \\\n",
      "0      Routine childhood vaccinations  should be man...   \n",
      "1      Routine childhood vaccinations  should be man...   \n",
      "2      Routine childhood vaccinations  should be man...   \n",
      "3      Routine childhood vaccinations  should be man...   \n",
      "4     Routine child vaccinations isn't mandatory sin...   \n",
      "...                                                 ...   \n",
      "3421  yes, there is some strong content on social me...   \n",
      "3422  you may create a chemical reaction that affect...   \n",
      "3423  you may create a chemical reaction that affect...   \n",
      "3424  you may create a chemical reaction that affect...   \n",
      "3425  you may create a chemical reaction that affect...   \n",
      "\n",
      "                                             hypothesis  label  prediction  \\\n",
      "0              Routine child vaccinations are effective      0           0   \n",
      "1                         Child vaccination saves lives      0           0   \n",
      "2     Routine child vaccinations are necessary to pr...      0           1   \n",
      "3     Routine child vaccinations should be mandatory...      1           1   \n",
      "4     Routine child vaccinations, or their side effe...      0           1   \n",
      "...                                                 ...    ...         ...   \n",
      "3421  Social media regulation is required to deal wi...      0           0   \n",
      "3422  Routine child vaccinations are not necessary t...      0           0   \n",
      "3423  Routine child vaccinations, or their side effe...      1           1   \n",
      "3424     Mandatory vaccination contradicts basic rights      0           0   \n",
      "3425        The parents and not the state should decide      0           0   \n",
      "\n",
      "      probability  \n",
      "0        0.851383  \n",
      "1        0.953045  \n",
      "2        0.981344  \n",
      "3        0.999903  \n",
      "4        0.950211  \n",
      "...           ...  \n",
      "3421     0.556897  \n",
      "3422     0.982927  \n",
      "3423     0.983050  \n",
      "3424     0.998719  \n",
      "3425     0.999867  \n",
      "\n",
      "[3426 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(all_probabilities)\n",
    "new_test_df = pd.read_csv('./result/KPM_official_test.csv')\n",
    "print(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  topic  \\\n",
      "0        Routine child vaccinations should be mandatory   \n",
      "1        Routine child vaccinations should be mandatory   \n",
      "2        Routine child vaccinations should be mandatory   \n",
      "3        Routine child vaccinations should be mandatory   \n",
      "4        Routine child vaccinations should be mandatory   \n",
      "...                                                 ...   \n",
      "3421  Social media platforms should be regulated by ...   \n",
      "3422     Routine child vaccinations should be mandatory   \n",
      "3423     Routine child vaccinations should be mandatory   \n",
      "3424     Routine child vaccinations should be mandatory   \n",
      "3425     Routine child vaccinations should be mandatory   \n",
      "\n",
      "                                                premise  \\\n",
      "0      Routine childhood vaccinations  should be man...   \n",
      "1      Routine childhood vaccinations  should be man...   \n",
      "2      Routine childhood vaccinations  should be man...   \n",
      "3      Routine childhood vaccinations  should be man...   \n",
      "4     Routine child vaccinations isn't mandatory sin...   \n",
      "...                                                 ...   \n",
      "3421  yes, there is some strong content on social me...   \n",
      "3422  you may create a chemical reaction that affect...   \n",
      "3423  you may create a chemical reaction that affect...   \n",
      "3424  you may create a chemical reaction that affect...   \n",
      "3425  you may create a chemical reaction that affect...   \n",
      "\n",
      "                                             hypothesis  label  prediction  \\\n",
      "0              Routine child vaccinations are effective      0           0   \n",
      "1                         Child vaccination saves lives      0           0   \n",
      "2     Routine child vaccinations are necessary to pr...      0           1   \n",
      "3     Routine child vaccinations should be mandatory...      1           1   \n",
      "4     Routine child vaccinations, or their side effe...      0           1   \n",
      "...                                                 ...    ...         ...   \n",
      "3421  Social media regulation is required to deal wi...      0           0   \n",
      "3422  Routine child vaccinations are not necessary t...      0           0   \n",
      "3423  Routine child vaccinations, or their side effe...      1           1   \n",
      "3424     Mandatory vaccination contradicts basic rights      0           0   \n",
      "3425        The parents and not the state should decide      0           0   \n",
      "\n",
      "      probability                                         logit  \n",
      "0        0.851383       [0.8513832688331604, 0.148616760969162]  \n",
      "1        0.953045     [0.9530447125434875, 0.04695533961057663]  \n",
      "2        0.981344    [0.018656279891729355, 0.9813437461853027]  \n",
      "3        0.999903   [9.680096263764426e-05, 0.9999032020568848]  \n",
      "4        0.950211    [0.049789465963840485, 0.9502105712890625]  \n",
      "...           ...                                           ...  \n",
      "3421     0.556897      [0.5568968653678894, 0.4431031048297882]  \n",
      "3422     0.982927     [0.982926607131958, 0.017073430120944977]  \n",
      "3423     0.983050    [0.016949782148003578, 0.9830501675605774]  \n",
      "3424     0.998719   [0.9987194538116455, 0.0012805949663743377]  \n",
      "3425     0.999867  [0.9998667240142822, 0.00013328522618394345]  \n",
      "\n",
      "[3426 rows x 7 columns]\n",
      "DataFrame has been saved to ./result/KPM_official_test.csv\n"
     ]
    }
   ],
   "source": [
    "new_test_df['logit'] = all_probabilities\n",
    "print(new_test_df)\n",
    "new_test_df.to_csv('./result/KPM_official_test.csv', index=False)\n",
    "print(f\"DataFrame has been saved to {'./result/KPM_official_test.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['arg_id', 'argument', 'topic', 'stance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "argument_df = pd.read_csv('./data/arguments_test.csv')\n",
    "print(argument_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['key_point_id', 'key_point', 'topic', 'stance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "kp_df = pd.read_csv('./data/key_points_test.csv')\n",
    "print(kp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3923\n",
      "                                               topic  stance     arg_id  \\\n",
      "0     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "1     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "2     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "3     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "4     Routine child vaccinations should be mandatory      -1    arg_0_1   \n",
      "...                                              ...     ...        ...   \n",
      "3918            The USA is a good country to live in       1  arg_2_209   \n",
      "3919            The USA is a good country to live in       1  arg_2_209   \n",
      "3920            The USA is a good country to live in       1  arg_2_209   \n",
      "3921            The USA is a good country to live in       1  arg_2_209   \n",
      "3922            The USA is a good country to live in       1  arg_2_209   \n",
      "\n",
      "                                               argument key_point_id  \\\n",
      "0     Routine child vaccinations isn't mandatory sin...       kp_0_0   \n",
      "1     Routine child vaccinations isn't mandatory sin...       kp_0_1   \n",
      "2     Routine child vaccinations isn't mandatory sin...       kp_0_2   \n",
      "3     Routine child vaccinations isn't mandatory sin...       kp_0_3   \n",
      "4     Routine child vaccinations should not be manda...       kp_0_0   \n",
      "...                                                 ...          ...   \n",
      "3918  yes, is a good country, beacause have good edu...       kp_2_9   \n",
      "3919  yes, is a good country, beacause have good edu...      kp_2_10   \n",
      "3920  yes, is a good country, beacause have good edu...      kp_2_11   \n",
      "3921  yes, is a good country, beacause have good edu...      kp_2_12   \n",
      "3922  yes, is a good country, beacause have good edu...      kp_2_13   \n",
      "\n",
      "                                              key_point  \n",
      "0     Routine child vaccinations, or their side effe...  \n",
      "1        Mandatory vaccination contradicts basic rights  \n",
      "2           The parents and not the state should decide  \n",
      "3     Routine child vaccinations are not necessary t...  \n",
      "4     Routine child vaccinations, or their side effe...  \n",
      "...                                                 ...  \n",
      "3918              The US has a great environment/nature  \n",
      "3919                       The US is a powerful country  \n",
      "3920  The US has a good economy/high standard of living  \n",
      "3921    The US has a good health and education systems   \n",
      "3922                    The US has great people/culture  \n",
      "\n",
      "[3923 rows x 6 columns]\n",
      "Index(['topic', 'stance', 'arg_id', 'argument', 'key_point_id', 'key_point'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for index,row in argument_df.iterrows():\n",
    "    filtered_kp = kp_df[(kp_df['topic'] == row['topic']) & (kp_df['stance'] == row['stance'])]\n",
    "    filtered_kp_list = filtered_kp.values.tolist()\n",
    "    for line in filtered_kp_list:\n",
    "        test_data.append([row['topic'],row['stance'],row['arg_id'],row['argument'],line[0],line[1]])\n",
    "print(len(test_data))\n",
    "\n",
    "header = ['topic','stance','arg_id','argument','key_point_id','key_point']\n",
    "df = pd.DataFrame(test_data, columns=header)\n",
    "print(df)\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to ./data/KPM_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('./data/KPM_test_data.csv', index=False)\n",
    "print(f\"DataFrame has been saved to {'./data/KPM_test_data.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'topic', 'stance', 'arg_id', 'argument',\n",
      "       'key_point_id', 'key_point', 'confidence_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Add new header confidence_score\n",
    "df = pd.read_csv('./data/KPM_test_data.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df['confidence_score'] = ''\n",
    "# df.to_csv('./data/KPM_test_data.csv')\n",
    "# print(f\"DataFrame has been saved to {'./data/KPM_test_data.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cross-encoder/nli-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "[0.04978947713971138, 0.9502105712890625]\n",
      "0: 0.04978947713971138\n",
      "[0.9856218695640564, 0.01437812577933073]\n",
      "1: 0.9856218695640564\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained the model and saved a checkpoint\n",
    "checkpoint_path = './checkpoint/nli_model-epoch=01-val_loss=0.37.ckpt'\n",
    "# Load the model from the checkpoint\n",
    "model_name = \"cross-encoder/nli-distilroberta-base\"\n",
    "num_classes = 2\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "learning_rate = 5e-05\n",
    "weight_decay = 0.001\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_classes, ignore_mismatched_sizes = True)\n",
    "loaded_model = KPM.load_from_checkpoint(model=model, checkpoint_path=checkpoint_path)\n",
    "print(\"hello world\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "\n",
    "# Make predictions on the test set with probabilities\n",
    "\n",
    "all_probabilities = []\n",
    "df = pd.read_csv('./data/KPM_test_data.csv')\n",
    "for index, row in df.iloc[:2].iterrows():\n",
    "    premise = row['argument']+tokenizer.sep_token+row['topic']\n",
    "    hypothesis = row['key_point']+tokenizer.sep_token+row['topic']\n",
    "    encoding = tokenizer(\n",
    "            premise,\n",
    "            hypothesis,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    with torch.no_grad():\n",
    "        logits = loaded_model(**encoding).logits\n",
    "        print(F.softmax(logits, dim=1).tolist()[0])\n",
    "        probabilities = F.softmax(logits, dim=1).tolist()[0][0]\n",
    "    print(str(index)+\": \"+str(probabilities))\n",
    "    df.at[index,'confidence_score'] = probabilities\n",
    "    # all_probabilities.append(probabilities)\n",
    "\n",
    "df.to_csv('./data/KPM_test_data.csv', index=False)\n",
    "print(\"Add new data successfully!!!!!\")\n",
    "# print(\"Finished\")\n",
    "# print(all_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make output json file for automatically evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n",
      "Index(['arg_id', 'argument', 'topic', 'stance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "argument_df = pd.read_csv('./data/arguments_test.csv')\n",
    "print(len(argument_df))\n",
    "print(argument_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3923\n",
      "      Unnamed: 0                                           topic  stance  \\\n",
      "0              0  Routine child vaccinations should be mandatory      -1   \n",
      "1              1  Routine child vaccinations should be mandatory      -1   \n",
      "2              2  Routine child vaccinations should be mandatory      -1   \n",
      "3              3  Routine child vaccinations should be mandatory      -1   \n",
      "4              4  Routine child vaccinations should be mandatory      -1   \n",
      "...          ...                                             ...     ...   \n",
      "3918        3918            The USA is a good country to live in       1   \n",
      "3919        3919            The USA is a good country to live in       1   \n",
      "3920        3920            The USA is a good country to live in       1   \n",
      "3921        3921            The USA is a good country to live in       1   \n",
      "3922        3922            The USA is a good country to live in       1   \n",
      "\n",
      "         arg_id                                           argument  \\\n",
      "0       arg_0_0  Routine child vaccinations isn't mandatory sin...   \n",
      "1       arg_0_0  Routine child vaccinations isn't mandatory sin...   \n",
      "2       arg_0_0  Routine child vaccinations isn't mandatory sin...   \n",
      "3       arg_0_0  Routine child vaccinations isn't mandatory sin...   \n",
      "4       arg_0_1  Routine child vaccinations should not be manda...   \n",
      "...         ...                                                ...   \n",
      "3918  arg_2_209  yes, is a good country, beacause have good edu...   \n",
      "3919  arg_2_209  yes, is a good country, beacause have good edu...   \n",
      "3920  arg_2_209  yes, is a good country, beacause have good edu...   \n",
      "3921  arg_2_209  yes, is a good country, beacause have good edu...   \n",
      "3922  arg_2_209  yes, is a good country, beacause have good edu...   \n",
      "\n",
      "     key_point_id                                          key_point  \\\n",
      "0          kp_0_0  Routine child vaccinations, or their side effe...   \n",
      "1          kp_0_1     Mandatory vaccination contradicts basic rights   \n",
      "2          kp_0_2        The parents and not the state should decide   \n",
      "3          kp_0_3  Routine child vaccinations are not necessary t...   \n",
      "4          kp_0_0  Routine child vaccinations, or their side effe...   \n",
      "...           ...                                                ...   \n",
      "3918       kp_2_9              The US has a great environment/nature   \n",
      "3919      kp_2_10                       The US is a powerful country   \n",
      "3920      kp_2_11  The US has a good economy/high standard of living   \n",
      "3921      kp_2_12    The US has a good health and education systems    \n",
      "3922      kp_2_13                    The US has great people/culture   \n",
      "\n",
      "      confidence_score  \n",
      "0             0.950211  \n",
      "1             0.014378  \n",
      "2             0.000360  \n",
      "3             0.824957  \n",
      "4             0.961748  \n",
      "...                ...  \n",
      "3918          0.005322  \n",
      "3919          0.386281  \n",
      "3920          0.047338  \n",
      "3921          0.425297  \n",
      "3922          0.043208  \n",
      "\n",
      "[3923 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/KPM_test_data.csv')\n",
    "# test_df['confidence_score'] = 1- test_df['confidence_score']\n",
    "print(len(test_df))\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               topic  stance     arg_id  \\\n",
      "0     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "1     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "2     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "3     Routine child vaccinations should be mandatory      -1    arg_0_0   \n",
      "4     Routine child vaccinations should be mandatory      -1    arg_0_1   \n",
      "...                                              ...     ...        ...   \n",
      "3918            The USA is a good country to live in       1  arg_2_209   \n",
      "3919            The USA is a good country to live in       1  arg_2_209   \n",
      "3920            The USA is a good country to live in       1  arg_2_209   \n",
      "3921            The USA is a good country to live in       1  arg_2_209   \n",
      "3922            The USA is a good country to live in       1  arg_2_209   \n",
      "\n",
      "                                               argument key_point_id  \\\n",
      "0     Routine child vaccinations isn't mandatory sin...       kp_0_0   \n",
      "1     Routine child vaccinations isn't mandatory sin...       kp_0_1   \n",
      "2     Routine child vaccinations isn't mandatory sin...       kp_0_2   \n",
      "3     Routine child vaccinations isn't mandatory sin...       kp_0_3   \n",
      "4     Routine child vaccinations should not be manda...       kp_0_0   \n",
      "...                                                 ...          ...   \n",
      "3918  yes, is a good country, beacause have good edu...       kp_2_9   \n",
      "3919  yes, is a good country, beacause have good edu...      kp_2_10   \n",
      "3920  yes, is a good country, beacause have good edu...      kp_2_11   \n",
      "3921  yes, is a good country, beacause have good edu...      kp_2_12   \n",
      "3922  yes, is a good country, beacause have good edu...      kp_2_13   \n",
      "\n",
      "                                              key_point  confidence_score  \n",
      "0     Routine child vaccinations, or their side effe...          0.950211  \n",
      "1        Mandatory vaccination contradicts basic rights          0.014378  \n",
      "2           The parents and not the state should decide          0.000360  \n",
      "3     Routine child vaccinations are not necessary t...          0.824957  \n",
      "4     Routine child vaccinations, or their side effe...          0.961748  \n",
      "...                                                 ...               ...  \n",
      "3918              The US has a great environment/nature          0.005322  \n",
      "3919                       The US is a powerful country          0.386281  \n",
      "3920  The US has a good economy/high standard of living          0.047338  \n",
      "3921    The US has a good health and education systems           0.425297  \n",
      "3922                    The US has great people/culture          0.043208  \n",
      "\n",
      "[3923 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop(test_df.columns[0], axis=1)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add new data successfully!!!!!\n"
     ]
    }
   ],
   "source": [
    "# test_df.to_csv('./data/KPM_test_data.csv', index=False)\n",
    "# print(\"Add new data successfully!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['topic', 'stance', 'arg_id', 'argument', 'key_point_id', 'key_point',\n",
      "       '4_7_8_15', '0_1_2_3', '5_6_9_10', '11_12_13_14', '16_17_18_19',\n",
      "       '20_21_22_23', '24_25_26_27', 'avg', 'gpt4', 'llama2', 'qwen'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('./data/KPM_test_data.csv')\n",
    "print(test_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arg_0_0': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_1': {'kp_0_0': 0.7, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.6}, 'arg_0_2': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_3': {'kp_0_0': 0.5, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_4': {'kp_0_0': 0.7, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.7}, 'arg_0_5': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_6': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_7': {'kp_0_0': 0.3, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_8': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_9': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_10': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_11': {'kp_0_0': 0.7, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_12': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_13': {'kp_0_0': 0.7, 'kp_0_1': 0.3, 'kp_0_2': 0.4, 'kp_0_3': 0.3}, 'arg_0_14': {'kp_0_0': 0.6, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.6}, 'arg_0_15': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_16': {'kp_0_0': 0.7, 'kp_0_1': 0.3, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_17': {'kp_0_0': 0.2, 'kp_0_1': 0.7, 'kp_0_2': 0.8, 'kp_0_3': 0.2}, 'arg_0_18': {'kp_0_0': 0.2, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_19': {'kp_0_0': 0.3, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_20': {'kp_0_0': 0.3, 'kp_0_1': 0.8, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_21': {'kp_0_0': 0.5, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_22': {'kp_0_0': 0.7, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.7}, 'arg_0_23': {'kp_0_0': 0.8, 'kp_0_1': 0.7, 'kp_0_2': 0.8, 'kp_0_3': 0.7}, 'arg_0_24': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_25': {'kp_0_0': 0.7, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.7}, 'arg_0_26': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.7}, 'arg_0_27': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_28': {'kp_0_0': 0.7, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_29': {'kp_0_0': 0.5, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_30': {'kp_0_0': 0.7, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_31': {'kp_0_0': 0.3, 'kp_0_1': 0.7, 'kp_0_2': 0.8, 'kp_0_3': 0.3}, 'arg_0_32': {'kp_0_0': 0.5, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_33': {'kp_0_0': 0.7, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_34': {'kp_0_0': 0.2, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_35': {'kp_0_0': 0.5, 'kp_0_1': 0.3, 'kp_0_2': 0.8, 'kp_0_3': 0.2}, 'arg_0_36': {'kp_0_0': 0.3, 'kp_0_1': 0.4, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_37': {'kp_0_0': 0.3, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_38': {'kp_0_0': 0.5, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_39': {'kp_0_0': 0.3, 'kp_0_1': 0.2, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_40': {'kp_0_0': 0.3, 'kp_0_1': 0.2, 'kp_0_2': 0.7, 'kp_0_3': 0.7}, 'arg_0_41': {'kp_0_0': 0.2, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_42': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_43': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_44': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_45': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_46': {'kp_0_0': 0.3, 'kp_0_1': 0.7, 'kp_0_2': 0.4, 'kp_0_3': 0.3}, 'arg_0_47': {'kp_0_0': 0.2, 'kp_0_1': 0.8, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_48': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_49': {'kp_0_0': 0.2, 'kp_0_1': 0.8, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_50': {'kp_0_0': 0.8, 'kp_0_1': 0.3, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_51': {'kp_0_0': 0.2, 'kp_0_1': 0.4, 'kp_0_2': 0.8, 'kp_0_3': 0.2}, 'arg_0_52': {'kp_0_0': 0.2, 'kp_0_1': 0.8, 'kp_0_2': 0.7, 'kp_0_3': 0.7}, 'arg_0_53': {'kp_0_0': 0.3, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_54': {'kp_0_0': 0.5, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_55': {'kp_0_0': 0.5, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_56': {'kp_0_0': 0.2, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_57': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_58': {'kp_0_0': 0.2, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_59': {'kp_0_0': 0.8, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_60': {'kp_0_0': 0.7, 'kp_0_1': 0.4, 'kp_0_2': 0.4, 'kp_0_3': 0.3}, 'arg_0_61': {'kp_0_0': 0.2, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_62': {'kp_0_0': 0.6, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_63': {'kp_0_0': 0.2, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.7}, 'arg_0_64': {'kp_0_0': 0.7, 'kp_0_1': 0.8, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_65': {'kp_0_0': 0.5, 'kp_0_1': 0.4, 'kp_0_2': 0.4, 'kp_0_3': 0.2}, 'arg_0_66': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_67': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.4, 'kp_0_3': 0.2}, 'arg_0_68': {'kp_0_0': 0.3, 'kp_0_1': 0.5, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_69': {'kp_0_0': 0.5, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_70': {'kp_0_0': 0.8, 'kp_0_1': 0.4, 'kp_0_2': 0.4, 'kp_0_3': 0.2}, 'arg_0_71': {'kp_0_0': 0.3, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.4}, 'arg_0_72': {'kp_0_0': 0.5, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_73': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_74': {'kp_0_0': 0.6, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_75': {'kp_0_0': 0.5, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.5}, 'arg_0_76': {'kp_0_0': 0.2, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.4}, 'arg_0_77': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_78': {'kp_0_0': 0.2, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_79': {'kp_0_0': 0.7, 'kp_0_1': 0.6, 'kp_0_2': 0.6, 'kp_0_3': 0.7}, 'arg_0_80': {'kp_0_0': 0.7, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_81': {'kp_0_0': 0.2, 'kp_0_1': 0.4, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_82': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_83': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_84': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_85': {'kp_0_0': 0.8, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_86': {'kp_0_0': 0.5, 'kp_0_1': 0.3, 'kp_0_2': 0.5, 'kp_0_3': 0.7}, 'arg_0_87': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_88': {'kp_0_0': 0.5, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_89': {'kp_0_0': 0.3, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_90': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_91': {'kp_0_0': 0.5, 'kp_0_1': 0.3, 'kp_0_2': 0.8, 'kp_0_3': 0.2}, 'arg_0_92': {'kp_0_0': 0.8, 'kp_0_1': 0.6, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_93': {'kp_0_0': 0.7, 'kp_0_1': 0.2, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_94': {'kp_0_0': 0.7, 'kp_0_1': 0.3, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_95': {'kp_0_0': 0.5, 'kp_0_1': 0.3, 'kp_0_2': 0.7, 'kp_0_3': 0.2}, 'arg_0_96': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_97': {'kp_0_0': 0.7, 'kp_0_1': 0.3, 'kp_0_2': 0.3, 'kp_0_3': 0.3}, 'arg_0_98': {'kp_0_0': 0.8, 'kp_0_1': 0.7, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_99': {'kp_0_0': 0.8, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_100': {'kp_0_0': 0.5, 'kp_0_1': 0.7, 'kp_0_2': 0.7, 'kp_0_3': 0.3}, 'arg_0_101': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.4, 'kp_0_3': 0.2}, 'arg_0_102': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_103': {'kp_0_0': 0.5, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_104': {'kp_0_0': 0.8, 'kp_0_1': 0.5, 'kp_0_2': 0.3, 'kp_0_3': 0.2}, 'arg_0_105': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_106': {'kp_0_0': 0.2, 'kp_0_1': 0.2, 'kp_0_2': 0.5, 'kp_0_3': 0.3}, 'arg_0_107': {'kp_0_0': 0.4, 'kp_0_1': 0.2, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_108': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_109': {'kp_0_0': 0.7, 'kp_0_1': 0.6, 'kp_0_2': 0.2, 'kp_0_3': 0.2}, 'arg_0_110': {'kp_0_0': 0.7, 'kp_0_1': 0.5, 'kp_0_2': 0.5, 'kp_0_3': 0.5}, 'arg_0_111': {'kp_0_0': 0.5, 'kp_0_1': 0.4, 'kp_0_2': 0.5, 'kp_0_3': 0.2}, 'arg_0_112': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_113': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_114': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_115': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_116': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_117': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.8}, 'arg_0_118': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_119': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_120': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_121': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_122': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_123': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_124': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_125': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_126': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_127': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_128': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_129': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_130': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_131': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_132': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_133': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_134': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_135': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_136': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_137': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_138': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_139': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_140': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_141': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_142': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_143': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_144': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_145': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_146': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_147': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_148': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_149': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_150': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_151': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_152': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_153': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_154': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_155': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_156': {'kp_0_4': 0.5, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_157': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_158': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_159': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.7}, 'arg_0_160': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_161': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_162': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_163': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_164': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_165': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_166': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_167': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_168': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.7}, 'arg_0_169': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_170': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_171': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_172': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_173': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_174': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_175': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_176': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_177': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_178': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_179': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_180': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_181': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_182': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_183': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_184': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_185': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.7}, 'arg_0_186': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_187': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.7}, 'arg_0_188': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_189': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_190': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_191': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_192': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_193': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_194': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_195': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_196': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_197': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_198': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_199': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_200': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_201': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_202': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_203': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_204': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_205': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_206': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_207': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_208': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_209': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_210': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_211': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_212': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_213': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_214': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_215': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_216': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_217': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_218': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_219': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_220': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_221': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_222': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_223': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_224': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_225': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_226': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_227': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_228': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_229': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_230': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_231': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_232': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.8}, 'arg_0_233': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_234': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_235': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_236': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_237': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_238': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.8}, 'arg_0_239': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_240': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_241': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_242': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_243': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_244': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_245': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_246': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_247': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_248': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_249': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_250': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_251': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_252': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_253': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_254': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_255': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_256': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_257': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_258': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_259': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_260': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_261': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_262': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_263': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_264': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_265': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_266': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_267': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_268': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_269': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_270': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_271': {'kp_0_4': 0.7, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_272': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.7, 'kp_0_8': 0.7}, 'arg_0_273': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_274': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_275': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_276': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_277': {'kp_0_4': 0.7, 'kp_0_5': 0.7, 'kp_0_6': 0.7, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_278': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_0_279': {'kp_0_4': 0.8, 'kp_0_5': 0.8, 'kp_0_6': 0.8, 'kp_0_7': 0.8, 'kp_0_8': 0.8}, 'arg_1_0': {'kp_1_0': 0.7, 'kp_1_1': 0.3, 'kp_1_2': 0.7, 'kp_1_3': 0.2, 'kp_1_4': 0.8}, 'arg_1_1': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_2': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_3': {'kp_1_0': 0.3, 'kp_1_1': 0.3, 'kp_1_2': 0.8, 'kp_1_3': 0.3, 'kp_1_4': 0.5}, 'arg_1_4': {'kp_1_0': 0.2, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.3, 'kp_1_4': 0.7}, 'arg_1_5': {'kp_1_0': 0.5, 'kp_1_1': 0.6, 'kp_1_2': 0.6, 'kp_1_3': 0.7, 'kp_1_4': 0.8}, 'arg_1_6': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_7': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_8': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_9': {'kp_1_0': 0.3, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_10': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_11': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_12': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_13': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.6, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_14': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_15': {'kp_1_0': 0.6, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_16': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_17': {'kp_1_0': 0.6, 'kp_1_1': 0.5, 'kp_1_2': 0.6, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_18': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_19': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_20': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_21': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_22': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_23': {'kp_1_0': 0.3, 'kp_1_1': 0.3, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_24': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_25': {'kp_1_0': 0.3, 'kp_1_1': 0.4, 'kp_1_2': 0.8, 'kp_1_3': 0.3, 'kp_1_4': 0.5}, 'arg_1_26': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_27': {'kp_1_0': 0.4, 'kp_1_1': 0.5, 'kp_1_2': 0.6, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_28': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_29': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_30': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.2, 'kp_1_3': 0.2, 'kp_1_4': 0.2}, 'arg_1_31': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.6, 'kp_1_4': 0.5}, 'arg_1_32': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_33': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_34': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.2, 'kp_1_3': 0.6, 'kp_1_4': 0.5}, 'arg_1_35': {'kp_1_0': 0.7, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.6, 'kp_1_4': 0.5}, 'arg_1_36': {'kp_1_0': 0.4, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.2, 'kp_1_4': 0.5}, 'arg_1_37': {'kp_1_0': 0.5, 'kp_1_1': 0.2, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_38': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.2, 'kp_1_3': 0.5, 'kp_1_4': 0.2}, 'arg_1_39': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_40': {'kp_1_0': 0.6, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_41': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.2}, 'arg_1_42': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_43': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.6, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_44': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.2, 'kp_1_3': 0.4, 'kp_1_4': 0.3}, 'arg_1_45': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_46': {'kp_1_0': 0.5, 'kp_1_1': 0.8, 'kp_1_2': 0.5, 'kp_1_3': 0.6, 'kp_1_4': 0.5}, 'arg_1_47': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_48': {'kp_1_0': 0.7, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_49': {'kp_1_0': 0.4, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_50': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_51': {'kp_1_0': 0.6, 'kp_1_1': 0.5, 'kp_1_2': 0.6, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_52': {'kp_1_0': 0.6, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.6, 'kp_1_4': 0.5}, 'arg_1_53': {'kp_1_0': 0.3, 'kp_1_1': 0.3, 'kp_1_2': 0.3, 'kp_1_3': 0.3, 'kp_1_4': 0.3}, 'arg_1_54': {'kp_1_0': 0.2, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_55': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_56': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_57': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.7, 'kp_1_3': 0.6, 'kp_1_4': 0.6}, 'arg_1_58': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_59': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.6, 'kp_1_4': 0.7}, 'arg_1_60': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_61': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.3, 'kp_1_4': 0.4}, 'arg_1_62': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_63': {'kp_1_0': 0.5, 'kp_1_1': 0.8, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_64': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.3, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_65': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_66': {'kp_1_0': 0.7, 'kp_1_1': 0.8, 'kp_1_2': 0.8, 'kp_1_3': 0.7, 'kp_1_4': 0.7}, 'arg_1_67': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.6, 'kp_1_3': 0.8, 'kp_1_4': 0.4}, 'arg_1_68': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.7, 'kp_1_3': 0.7, 'kp_1_4': 0.3}, 'arg_1_69': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.4, 'kp_1_4': 0.5}, 'arg_1_70': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.7, 'kp_1_3': 0.3, 'kp_1_4': 0.7}, 'arg_1_71': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_72': {'kp_1_0': 0.5, 'kp_1_1': 0.8, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_73': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.6, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_74': {'kp_1_0': 0.2, 'kp_1_1': 0.2, 'kp_1_2': 0.2, 'kp_1_3': 0.2, 'kp_1_4': 0.5}, 'arg_1_75': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.5, 'kp_1_3': 0.3, 'kp_1_4': 0.7}, 'arg_1_76': {'kp_1_0': 0.5, 'kp_1_1': 0.6, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_77': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_78': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.2}, 'arg_1_79': {'kp_1_0': 0.5, 'kp_1_1': 0.8, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_80': {'kp_1_0': 0.6, 'kp_1_1': 0.8, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.8}, 'arg_1_81': {'kp_1_0': 0.5, 'kp_1_1': 0.7, 'kp_1_2': 0.6, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_82': {'kp_1_0': 0.5, 'kp_1_1': 0.6, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_83': {'kp_1_0': 0.5, 'kp_1_1': 0.2, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_84': {'kp_1_0': 0.4, 'kp_1_1': 0.8, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_85': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_86': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_87': {'kp_1_0': 0.2, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_88': {'kp_1_0': 0.5, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.3, 'kp_1_4': 0.5}, 'arg_1_89': {'kp_1_0': 0.2, 'kp_1_1': 0.3, 'kp_1_2': 0.5, 'kp_1_3': 0.2, 'kp_1_4': 0.5}, 'arg_1_90': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.8, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_91': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.5}, 'arg_1_92': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.3, 'kp_1_4': 0.8}, 'arg_1_93': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_94': {'kp_1_0': 0.6, 'kp_1_1': 0.7, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_95': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_96': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.7, 'kp_1_3': 0.5, 'kp_1_4': 0.7}, 'arg_1_97': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.8, 'kp_1_4': 0.5}, 'arg_1_98': {'kp_1_0': 0.5, 'kp_1_1': 0.5, 'kp_1_2': 0.5, 'kp_1_3': 0.7, 'kp_1_4': 0.5}, 'arg_1_99': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_100': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_101': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_102': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_103': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_104': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_105': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_106': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_107': {'kp_1_5': 0.7, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_108': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_109': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_110': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_111': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_112': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_113': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_114': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_115': {'kp_1_5': 0.5, 'kp_1_6': 0.5, 'kp_1_7': 0.7, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_116': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_117': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_118': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_119': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_120': {'kp_1_5': 0.8, 'kp_1_6': 0.5, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_121': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_122': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_123': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_124': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_125': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_126': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_127': {'kp_1_5': 0.7, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_128': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_129': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_130': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_131': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_132': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.7, 'kp_1_9': 0.8}, 'arg_1_133': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_134': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_135': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_136': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_137': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_138': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_139': {'kp_1_5': 0.7, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_140': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_141': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_142': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_143': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_144': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.7, 'kp_1_9': 0.8}, 'arg_1_145': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_146': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_147': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_148': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_149': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_150': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_151': {'kp_1_5': 0.5, 'kp_1_6': 0.6, 'kp_1_7': 0.6, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_152': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_153': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_154': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_155': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_156': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_157': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_158': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_159': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_160': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_161': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_162': {'kp_1_5': 0.7, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_163': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_164': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_165': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_166': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_167': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_168': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_169': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_170': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_171': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_172': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_173': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_174': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_175': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_176': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_177': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_178': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_179': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_180': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_181': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_182': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_183': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_184': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.7, 'kp_1_9': 0.8}, 'arg_1_185': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_186': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_187': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_188': {'kp_1_5': 0.5, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_189': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_190': {'kp_1_5': 0.7, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_191': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_192': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_193': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_194': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_195': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_196': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_197': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_198': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_199': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_200': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_201': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_202': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_203': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_204': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_205': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_206': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_207': {'kp_1_5': 0.8, 'kp_1_6': 0.6, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_208': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_209': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.7, 'kp_1_9': 0.7}, 'arg_1_210': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_211': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_212': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_213': {'kp_1_5': 0.8, 'kp_1_6': 0.6, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_214': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_215': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_216': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_217': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_218': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_219': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_220': {'kp_1_5': 0.8, 'kp_1_6': 0.6, 'kp_1_7': 0.7, 'kp_1_8': 0.8, 'kp_1_9': 0.7}, 'arg_1_221': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_222': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_223': {'kp_1_5': 0.6, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.5, 'kp_1_9': 0.7}, 'arg_1_224': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_225': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_226': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_227': {'kp_1_5': 0.7, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_228': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_229': {'kp_1_5': 0.7, 'kp_1_6': 0.6, 'kp_1_7': 0.6, 'kp_1_8': 0.7, 'kp_1_9': 0.6}, 'arg_1_230': {'kp_1_5': 0.8, 'kp_1_6': 0.7, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_231': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_1_232': {'kp_1_5': 0.8, 'kp_1_6': 0.8, 'kp_1_7': 0.8, 'kp_1_8': 0.8, 'kp_1_9': 0.8}, 'arg_2_0': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_1': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.4, 'kp_2_3': 0.7, 'kp_2_4': 0.5, 'kp_2_5': 0.5, 'kp_2_6': 0.5}, 'arg_2_2': {'kp_2_0': 0.4, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_3': {'kp_2_0': 0.2, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.3, 'kp_2_6': 0.2}, 'arg_2_4': {'kp_2_0': 0.3, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_5': {'kp_2_0': 0.5, 'kp_2_1': 0.2, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.3}, 'arg_2_6': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.7, 'kp_2_6': 0.2}, 'arg_2_7': {'kp_2_0': 0.4, 'kp_2_1': 0.3, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_8': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_9': {'kp_2_0': 0.2, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_10': {'kp_2_0': 0.2, 'kp_2_1': 0.3, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_11': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.4, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_12': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.3, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.3, 'kp_2_6': 0.3}, 'arg_2_13': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.5, 'kp_2_4': 0.5, 'kp_2_5': 0.5, 'kp_2_6': 0.5}, 'arg_2_14': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_15': {'kp_2_0': 0.7, 'kp_2_1': 0.3, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_16': {'kp_2_0': 0.2, 'kp_2_1': 0.3, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.3, 'kp_2_6': 0.2}, 'arg_2_17': {'kp_2_0': 0.3, 'kp_2_1': 0.4, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.7, 'kp_2_6': 0.5}, 'arg_2_18': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.7, 'kp_2_4': 0.7, 'kp_2_5': 0.5, 'kp_2_6': 0.7}, 'arg_2_19': {'kp_2_0': 0.4, 'kp_2_1': 0.7, 'kp_2_2': 0.4, 'kp_2_3': 0.8, 'kp_2_4': 0.6, 'kp_2_5': 0.8, 'kp_2_6': 0.7}, 'arg_2_20': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.5, 'kp_2_4': 0.5, 'kp_2_5': 0.5, 'kp_2_6': 0.5}, 'arg_2_21': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.3, 'kp_2_6': 0.5}, 'arg_2_22': {'kp_2_0': 0.4, 'kp_2_1': 0.3, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.4, 'kp_2_5': 0.8, 'kp_2_6': 0.2}, 'arg_2_23': {'kp_2_0': 0.5, 'kp_2_1': 0.2, 'kp_2_2': 0.3, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.3}, 'arg_2_24': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_25': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.3, 'kp_2_6': 0.2}, 'arg_2_26': {'kp_2_0': 0.4, 'kp_2_1': 0.4, 'kp_2_2': 0.4, 'kp_2_3': 0.3, 'kp_2_4': 0.7, 'kp_2_5': 0.3, 'kp_2_6': 0.3}, 'arg_2_27': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_28': {'kp_2_0': 0.5, 'kp_2_1': 0.4, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_29': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_30': {'kp_2_0': 0.2, 'kp_2_1': 0.4, 'kp_2_2': 0.4, 'kp_2_3': 0.2, 'kp_2_4': 0.4, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_31': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.4, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_32': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.2, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_33': {'kp_2_0': 0.2, 'kp_2_1': 0.4, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.4, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_34': {'kp_2_0': 0.4, 'kp_2_1': 0.4, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.5}, 'arg_2_35': {'kp_2_0': 0.3, 'kp_2_1': 0.3, 'kp_2_2': 0.6, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.7, 'kp_2_6': 0.2}, 'arg_2_36': {'kp_2_0': 0.7, 'kp_2_1': 0.2, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.3}, 'arg_2_37': {'kp_2_0': 0.2, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.7, 'kp_2_6': 0.2}, 'arg_2_38': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.7, 'kp_2_6': 0.2}, 'arg_2_39': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.3, 'kp_2_4': 0.5, 'kp_2_5': 0.3, 'kp_2_6': 0.3}, 'arg_2_40': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_41': {'kp_2_0': 0.6, 'kp_2_1': 0.5, 'kp_2_2': 0.6, 'kp_2_3': 0.2, 'kp_2_4': 0.6, 'kp_2_5': 0.5, 'kp_2_6': 0.5}, 'arg_2_42': {'kp_2_0': 0.5, 'kp_2_1': 0.4, 'kp_2_2': 0.4, 'kp_2_3': 0.7, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_43': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.2, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_44': {'kp_2_0': 0.4, 'kp_2_1': 0.4, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_45': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.4, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.3, 'kp_2_6': 0.2}, 'arg_2_46': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.4, 'kp_2_3': 0.3, 'kp_2_4': 0.5, 'kp_2_5': 0.3, 'kp_2_6': 0.3}, 'arg_2_47': {'kp_2_0': 0.7, 'kp_2_1': 0.4, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_48': {'kp_2_0': 0.4, 'kp_2_1': 0.4, 'kp_2_2': 0.5, 'kp_2_3': 0.5, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.5}, 'arg_2_49': {'kp_2_0': 0.8, 'kp_2_1': 0.4, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_50': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.3}, 'arg_2_51': {'kp_2_0': 0.3, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_52': {'kp_2_0': 0.4, 'kp_2_1': 0.3, 'kp_2_2': 0.4, 'kp_2_3': 0.7, 'kp_2_4': 0.4, 'kp_2_5': 0.7, 'kp_2_6': 0.7}, 'arg_2_53': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_54': {'kp_2_0': 0.4, 'kp_2_1': 0.4, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_55': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.8, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_56': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_57': {'kp_2_0': 0.3, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_58': {'kp_2_0': 0.4, 'kp_2_1': 0.7, 'kp_2_2': 0.7, 'kp_2_3': 0.4, 'kp_2_4': 0.6, 'kp_2_5': 0.7, 'kp_2_6': 0.4}, 'arg_2_59': {'kp_2_0': 0.4, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.5, 'kp_2_4': 0.5, 'kp_2_5': 0.5, 'kp_2_6': 0.5}, 'arg_2_60': {'kp_2_0': 0.7, 'kp_2_1': 0.5, 'kp_2_2': 0.7, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.5, 'kp_2_6': 0.2}, 'arg_2_61': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_62': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.4, 'kp_2_3': 0.2, 'kp_2_4': 0.3, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_63': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.5, 'kp_2_4': 0.5, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_64': {'kp_2_0': 0.2, 'kp_2_1': 0.2, 'kp_2_2': 0.5, 'kp_2_3': 0.2, 'kp_2_4': 0.7, 'kp_2_5': 0.2, 'kp_2_6': 0.2}, 'arg_2_65': {'kp_2_0': 0.5, 'kp_2_1': 0.5, 'kp_2_2': 0.5, 'kp_2_3': 0.7, 'kp_2_4': 0.6, 'kp_2_5': 0.5, 'kp_2_6': 0.2}, 'arg_2_66': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.8, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_67': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.8}, 'arg_2_68': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_69': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_70': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_71': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_72': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_73': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_74': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.8}, 'arg_2_75': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_76': {'kp_2_7': 0.5, 'kp_2_8': 0.5, 'kp_2_9': 0.8, 'kp_2_10': 0.4, 'kp_2_11': 0.5, 'kp_2_12': 0.4, 'kp_2_13': 0.5}, 'arg_2_77': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_78': {'kp_2_7': 0.7, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_79': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_80': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_81': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_82': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_83': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_84': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_85': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.8, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_86': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_87': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_88': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_89': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_90': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_91': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_92': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_93': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_94': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_95': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_96': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_97': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_98': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_99': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_100': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.6, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_101': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_102': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_103': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_104': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_105': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_106': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_107': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_108': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_109': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_110': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_111': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_112': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.6, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_113': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.8}, 'arg_2_114': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_115': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_116': {'kp_2_7': 0.7, 'kp_2_8': 0.6, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.7, 'kp_2_12': 0.5, 'kp_2_13': 0.5}, 'arg_2_117': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_118': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_119': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_120': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_121': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_122': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_123': {'kp_2_7': 0.7, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_124': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.5, 'kp_2_13': 0.7}, 'arg_2_125': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_126': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_127': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_128': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.4, 'kp_2_10': 0.6, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_129': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.4, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_130': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.6, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_131': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_132': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_133': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_134': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_135': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_136': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_137': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.4, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_138': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.6, 'kp_2_10': 0.6, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_139': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_140': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.6, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_141': {'kp_2_7': 0.7, 'kp_2_8': 0.5, 'kp_2_9': 0.8, 'kp_2_10': 0.4, 'kp_2_11': 0.5, 'kp_2_12': 0.4, 'kp_2_13': 0.5}, 'arg_2_142': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_143': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_144': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.8, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_145': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_146': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_147': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_148': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_149': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.8, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_150': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_151': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_152': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_153': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_154': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_155': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_156': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_157': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_158': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.8, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_159': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_160': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_161': {'kp_2_7': 0.7, 'kp_2_8': 0.6, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.5, 'kp_2_13': 0.5}, 'arg_2_162': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.5}, 'arg_2_163': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_164': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_165': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_166': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_167': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_168': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_169': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_170': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_171': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_172': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_173': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_174': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_175': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_176': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_177': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.8, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_178': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_179': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_180': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_181': {'kp_2_7': 0.7, 'kp_2_8': 0.5, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.5, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_182': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.8, 'kp_2_10': 0.6, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_183': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_184': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_185': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_186': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_187': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.6, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_188': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_189': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_190': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.6, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_191': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_192': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_193': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_194': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_195': {'kp_2_7': 0.7, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.5, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_196': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_197': {'kp_2_7': 0.7, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.5}, 'arg_2_198': {'kp_2_7': 0.5, 'kp_2_8': 0.5, 'kp_2_9': 0.5, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.5, 'kp_2_13': 0.5}, 'arg_2_199': {'kp_2_7': 0.5, 'kp_2_8': 0.5, 'kp_2_9': 0.4, 'kp_2_10': 0.4, 'kp_2_11': 0.7, 'kp_2_12': 0.5, 'kp_2_13': 0.5}, 'arg_2_200': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.5}, 'arg_2_201': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.7, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_202': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.7, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_203': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_204': {'kp_2_7': 0.8, 'kp_2_8': 0.7, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.7}, 'arg_2_205': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.8, 'kp_2_10': 0.4, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_206': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.6, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}, 'arg_2_207': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.7}, 'arg_2_208': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.7, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.7, 'kp_2_13': 0.8}, 'arg_2_209': {'kp_2_7': 0.8, 'kp_2_8': 0.8, 'kp_2_9': 0.5, 'kp_2_10': 0.5, 'kp_2_11': 0.8, 'kp_2_12': 0.8, 'kp_2_13': 0.8}}\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "arg_id = argument_df['arg_id'].values.tolist()\n",
    "for arg in arg_id:\n",
    "    filtered_df = test_df[test_df['arg_id'] == arg]\n",
    "    kp_id = filtered_df['key_point_id'].values.tolist()\n",
    "    score = filtered_df['llama2'].values.tolist()\n",
    "    result_dict = dict(zip(kp_id, score))\n",
    "    output_data.append(result_dict)\n",
    "final_result = dict(zip(arg_id,output_data))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file './result/llama2.json' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = './result/llama2.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(final_result, json_file)\n",
    "print(f\"JSON file '{file_path}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}